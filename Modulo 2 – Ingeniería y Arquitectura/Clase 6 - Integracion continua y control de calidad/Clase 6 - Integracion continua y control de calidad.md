# ğŸ§  Clase 6 - IntegraciÃ³n continua y control de calidad arquitectÃ³nica

*(MÃ³dulo 2 â€“ IngenierÃ­a y Arquitectura)*

## ğŸ§  Antes de empezar

Hasta ahora has construido una API que no solo funciona, sino que **se sostiene con dignidad**:

- Tiene capas separadas (API, servicio, repositorio).
- Los tests cubren sus funcionalidades bÃ¡sicas.
- Puedes cambiar de memoria a JSON sin romper nada.

Pero te falta lo mÃ¡s importante si quieres que este proyecto crezca:

> Que nadie (ni tÃº mismo en 3 semanas) pueda romperlo sin enterarse.
> 

AquÃ­ entra en juego la **IntegraciÃ³n Continua (CI)**:

Un sistema que lanza los tests automÃ¡ticamente **cada vez que haces push o abres un PR**.

Si todo va bien â†’ âœ…

Si algo se rompe â†’ âŒ GitHub te lo canta sin que nadie lo tenga que revisar a mano.

---

## ğŸ¯ Â¿QuÃ© vamos a montar hoy?

Una mini-fÃ¡brica que se encargue de:

1. Ejecutar los tests automÃ¡ticamente.
2. Avisarte si algo falla.
3. (MÃ¡s adelante) Medir cobertura, pasar linters, y desplegar.

No mÃ¡s â€œÂ¡en mi mÃ¡quina funciona!â€ ni â€œse me olvidÃ³ correr los testsâ€.

---

## ğŸ§ª Paso a paso (a mano)

### 1. Crea la carpeta donde viven los workflows de GitHub:

```bash
mkdir -p .github/workflows

```
Importante, esto es en la raiz de tu proyecto

Yâ€¦ Â¿recuerdas que en la clase 2 generamos un requirements.txt? metelo tambien en la raiz

### 2. Dentro, crea el archivo `ci.yml`:

```yaml
name: CI - Tests automÃ¡ticos

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main, dev]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Clonar el repo
        uses: actions/checkout@v4

      - name: Instalar Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ejecutar tests
        run: pytest -v

```

Guarda, haz commit, empuja la rama y abre PR.

GitHub va a lanzar automÃ¡ticamente el workflow y te dirÃ¡ si todo estÃ¡ OK o si se ha roto algo.

---

## ğŸ¤– OrquestaciÃ³n Multi-Agente: Tu EjÃ©rcito de Especialistas

Hasta ahora has trabajado con la IA como un "asistente general". Pero cuando construyes un proyecto completo (como este API de tareas), necesitas **especialistas que trabajen en equipo**.

AquÃ­ entra la **orquestaciÃ³n de agentes**: usar mÃºltiples agentes IA especializados, cada uno experto en su dominio, coordinados para lograr un objetivo comÃºn.

> **AnalogÃ­a**: No contratas a un "constructor general" para hacer tu casa. Contratas un arquitecto, un electricista, un plomero, un carpintero... cada uno experto en su Ã¡rea.

### ğŸ¯ Los 4 Agentes Especializados para este Proyecto

En el desarrollo del proyecto final del MÃ³dulo 2, vas a orquestar **4 agentes educacionales**:

#### 1ï¸âƒ£ **Clean Architecture Enforcer**
   - **Especialidad**: Validar arquitectura en capas y principios SOLID
   - **CuÃ¡ndo usarlo**: Al inicio (diseÃ±o) y al final (validaciÃ³n)
   - **QuÃ© detecta**: Violaciones de separaciÃ³n de capas, dependency inversion, single responsibility
   - **UbicaciÃ³n**: `.claude/agents/educational/clean-architecture-enforcer.md`

#### 2ï¸âƒ£ **FastAPI Design Coach**
   - **Especialidad**: DiseÃ±o profesional de endpoints FastAPI
   - **CuÃ¡ndo usarlo**: Al implementar endpoints, modelos Pydantic, async patterns
   - **QuÃ© detecta**: Endpoints no-RESTful, validaciÃ³n incompleta, blocking I/O en async
   - **UbicaciÃ³n**: `.claude/agents/educational/fastapi-design-coach.md`

#### 3ï¸âƒ£ **API Design Reviewer**
   - **Especialidad**: DiseÃ±o RESTful, HTTP semantics, OpenAPI documentation
   - **CuÃ¡ndo usarlo**: Al finalizar endpoints, antes de desplegar
   - **QuÃ© detecta**: Status codes incorrectos, responses inconsistentes, URLs no-RESTful
   - **UbicaciÃ³n**: `.claude/agents/educational/api-design-reviewer.md`

#### 4ï¸âƒ£ **Test Coverage Strategist** (Python Best Practices Coach)
   - **Especialidad**: Testing completo (unit + integration), coverage strategies
   - **CuÃ¡ndo usarlo**: DespuÃ©s de implementar cada feature
   - **QuÃ© detecta**: Tests faltantes, coverage gaps, test anti-patterns
   - **UbicaciÃ³n**: `.claude/agents/educational/python-best-practices-coach.md`

---

## ğŸ”„ Workflow Completo: Desarrollo del Proyecto Final con Agentes

AquÃ­ estÃ¡ el **workflow paso a paso** para desarrollar el proyecto final del MÃ³dulo 2 (API de tareas completa) usando orquestaciÃ³n de agentes:

### **Fase 1: DiseÃ±o ArquitectÃ³nico** (con Clean Architecture Enforcer)

**Objetivo**: Validar que tu diseÃ±o sigue arquitectura limpia ANTES de escribir cÃ³digo.

**Prompt para el agente**:
```markdown
Rol: Clean Architecture Enforcer
Contexto: Voy a desarrollar una API de tareas con FastAPI siguiendo arquitectura en capas.
Objetivo: Valida este diseÃ±o arquitectÃ³nico y sugiere mejoras.

DiseÃ±o propuesto:
- API Layer: FastAPI endpoints (api.py)
- Service Layer: LÃ³gica de negocio (servicio_tareas.py)
- Repository Layer:
  - Protocol (repositorio_base.py)
  - Implementaciones: RepositorioMemoria, RepositorioJSON

Â¿Este diseÃ±o sigue SOLID? Â¿QuÃ© violaciones ves? Â¿QuÃ© mejorarÃ­as?
```

**Output esperado del agente**:
- âœ… ValidaciÃ³n de separaciÃ³n de capas
- âœ… VerificaciÃ³n de Dependency Inversion
- âš ï¸ Sugerencias de mejora (ej: "AÃ±adir abstracciÃ³n de dependencias.py")
- ğŸ“š ExplicaciÃ³n de principios SOLID aplicados

**AcciÃ³n**: Ajustar el diseÃ±o segÃºn el feedback antes de codear.

---

### **Fase 2: ImplementaciÃ³n de Endpoints** (con FastAPI Design Coach)

**Objetivo**: Desarrollar endpoints profesionales con validaciÃ³n completa.

**Prompt para el agente**:
```markdown
Rol: FastAPI Design Coach
Contexto: Estoy implementando endpoints para mi API de tareas.
Objetivo: Revisa este endpoint y sugiere mejoras en diseÃ±o FastAPI.

Endpoint propuesto:
```python
@app.post("/tareas")
def crear_tarea(titulo: str, descripcion: str):
    tarea = servicio.crear_tarea(titulo, descripcion)
    return tarea
```

Â¿QuÃ© mejorarÃ­as en:
1. Pydantic models (validaciÃ³n)
2. Status codes HTTP
3. Response format
4. Async/await usage
5. Dependency injection
```

**Output esperado del agente**:
- âŒ Detecta: Falta Pydantic model, status code incorrecto (deberÃ­a ser 201), sin validaciÃ³n
- âœ… Sugiere: Crear `TareaCreate` (request) y `TareaResponse` (response), usar `status.HTTP_201_CREATED`, aÃ±adir validaciÃ³n con `Field(...)`
- ğŸ“š Explica: Por quÃ© separar request/response models, cuÃ¡ndo usar async

**AcciÃ³n**: Implementar el endpoint mejorado con Pydantic models completos.

---

### **Fase 3: ValidaciÃ³n REST** (con API Design Reviewer)

**Objetivo**: Asegurar que toda la API sigue estÃ¡ndares REST e HTTP.

**Prompt para el agente**:
```markdown
Rol: API Design Reviewer
Contexto: He completado todos los endpoints de mi API de tareas.
Objetivo: Audita la API completa y valida diseÃ±o RESTful.

Endpoints implementados:
- POST /tareas - Crear tarea
- GET /tareas - Listar tareas
- GET /tareas/{id} - Obtener tarea
- PUT /tareas/{id} - Actualizar tarea
- DELETE /tareas/{id} - Eliminar tarea
- PUT /tareas/{id}/completar - Marcar como completada

Â¿Son RESTful? Â¿Los status codes son correctos? Â¿Las responses son consistentes?
```

**Output esperado del agente**:
- âœ… Valida: POST/GET/PUT/DELETE correctos
- âš ï¸ Detecta: `/completar` no es RESTful (deberÃ­a ser PATCH con body)
- âœ… Sugiere: Cambiar a `PATCH /tareas/{id}` con `{"completada": true}`
- ğŸ“š Explica: Diferencia entre PUT (replace) y PATCH (partial update)

**AcciÃ³n**: Refactorizar endpoints no-RESTful segÃºn estÃ¡ndares.

---

### **Fase 4: Testing Completo** (con Test Coverage Strategist)

**Objetivo**: Asegurar cobertura completa de tests (unit + integration).

**Prompt para el agente**:
```markdown
Rol: Test Coverage Strategist (Python Best Practices Coach)
Contexto: He implementado mi API de tareas con todos los endpoints.
Objetivo: DiseÃ±a una estrategia completa de testing.

Features implementadas:
- CRUD completo de tareas
- 2 repositorios (Memoria, JSON)
- Service layer con business logic
- ValidaciÃ³n con Pydantic

Â¿QuÃ© tests necesito? Â¿DÃ³nde estÃ¡n los gaps de coverage?
```

**Output esperado del agente**:
- âœ… Estrategia de testing:
  - **Unit tests**: Service layer (business logic aislada)
  - **Integration tests**: Repositories (persistencia real)
  - **API tests**: Endpoints (con TestClient)
- âœ… Detecta gaps:
  - Casos edge (tÃ­tulos vacÃ­os, IDs inexistentes)
  - Error handling (404, 422)
  - ValidaciÃ³n de Pydantic
- ğŸ“š Explica: Diferencia entre unit/integration/API tests

**AcciÃ³n**: Implementar tests completos segÃºn la estrategia.

---

### **Fase 5: ValidaciÃ³n Final de Arquitectura** (de nuevo Clean Architecture Enforcer)

**Objetivo**: Verificar que la implementaciÃ³n final sigue el diseÃ±o arquitectÃ³nico.

**Prompt para el agente**:
```markdown
Rol: Clean Architecture Enforcer
Contexto: He completado la implementaciÃ³n de mi API de tareas.
Objetivo: Audita el cÃ³digo completo y valida arquitectura limpia.

Estructura final:
- api/api.py (200 lÃ­neas)
- api/servicio_tareas.py (150 lÃ­neas)
- api/repositorio_base.py (Protocol)
- api/repositorio_memoria.py
- api/repositorio_json.py
- tests/ (unit tests)
- tests_integrations/ (integration tests)

Â¿La arquitectura se mantiene limpia? Â¿Hay violaciones de SOLID?
```

**Output esperado del agente**:
- âœ… Valida: Capas separadas, dependency inversion correcta
- âš ï¸ Detecta: Si hay business logic en API layer (moverla a Service)
- âœ… Confirma: Repository pattern bien implementado
- ğŸ“š Explica: QuÃ© hacer cuando la app crezca (mÃ³dulos, DDD)

**AcciÃ³n**: Refactorizar violaciones detectadas.

---

## ğŸ§© GuÃ­a de OrquestaciÃ³n: Â¿CuÃ¡ndo usar quÃ© agente?

| **SituaciÃ³n** | **Agente a usar** | **Por quÃ©** |
|---------------|-------------------|-------------|
| DiseÃ±ando la estructura del proyecto | Clean Architecture Enforcer | Valida diseÃ±o ANTES de codear |
| Implementando un nuevo endpoint | FastAPI Design Coach | EnseÃ±a patrones FastAPI profesionales |
| Completaste todos los endpoints | API Design Reviewer | Audita REST compliance y consistencia |
| DespuÃ©s de cada feature | Test Coverage Strategist | Asegura testing completo |
| Antes de hacer PR | Clean Architecture Enforcer + API Design Reviewer | ValidaciÃ³n final doble |
| Encontraste bug en producciÃ³n | Todos en orden inverso | Root cause analysis por capas |

---

## ğŸ“ Ejercicio PrÃ¡ctico: Desarrollo Guiado por Agentes

**Objetivo**: Implementar el endpoint `GET /tareas/{id}/historial` (listar cambios de una tarea) usando los 4 agentes.

### Paso 1: DiseÃ±o con Clean Architecture Enforcer
- Pregunta dÃ³nde va la lÃ³gica (Â¿service? Â¿repository?)
- Valida que no rompes capas existentes

### Paso 2: ImplementaciÃ³n con FastAPI Design Coach
- Crea el endpoint siguiendo sus sugerencias
- Define Pydantic models apropiados
- Usa status codes correctos

### Paso 3: ValidaciÃ³n REST con API Design Reviewer
- Â¿`/historial` es RESTful?
- Â¿O deberÃ­a ser `/tareas/{id}/audit-log`?
- Â¿El formato de response es consistente?

### Paso 4: Testing con Test Coverage Strategist
- Â¿QuÃ© tests necesitas?
- Â¿Unit? Â¿Integration? Â¿API?
- Â¿Casos edge?

**Documenta en `notes.md`**:
- QuÃ© agente usaste en cada paso
- QuÃ© feedback te dio cada uno
- QuÃ© cambiÃ³ en tu implementaciÃ³n gracias a ellos

---

## ğŸ”§ Prompt Estructurado para CI/CD (bonus)

Ahora que entiendes orquestaciÃ³n de agentes, aquÃ­ estÃ¡ el prompt profesional para generar CI/CD con IA:

```markdown
Rol: DevOps Python Specialist + CI/CD Expert
Contexto: Tengo un proyecto FastAPI con:
- Arquitectura en capas (API, Service, Repository)
- Tests en pytest (unit + integration)
- Coverage target: 80%
- Linting: Ruff
- Security: Bandit

Objetivo: Crea un pipeline de GitHub Actions que:
1. Ejecute tests con coverage (fail si <80%)
2. Corra Ruff linting
3. Ejecute Bandit security scan
4. No permita merge si falla alguno
5. Use Python 3.12
6. Optimice con caching de dependencias

Formato: YAML limpio y comentado, explicando cada step.

Restricciones:
- Debe correr en ubuntu-latest
- Timeout de 10 minutos max
- Artifacts de coverage report
```

AsÃ­ obtienes una versiÃ³n profesional con todos los checks de calidad.

**Pero ahora sabes quÃ© hace cada parte** y puedes adaptarla, no solo copiarla a ciegas.

---

## ğŸ§­ Â¿Por quÃ© esto importa?

Hasta hoy, **tÃº ejecutabas los tests**.

A partir de ahora, **los tests se ejecutan solos**. Siempre.

Eso es ingenierÃ­a de verdad. No confiar en la memoria, sino en procesos automÃ¡ticos.

> Si alguien cambia RepositorioTareas y se carga el contrato, el PR no pasa.
> 
> 
> Si alguien olvida un test, la cobertura lo avisa.
> 
> Si alguien comete una burrada, la mÃ¡quina lo frena.
> 

---

## ğŸ› ï¸ Mini-ejercicio prÃ¡ctico

1. Crea la rama `feature/ci`.
2. AÃ±ade `.github/workflows/ci.yml`.
3. Haz push y abre PR.
4. Comprueba que GitHub lanza el workflow y los tests pasan.
5. Escribe en `notes.md`:
    - QuÃ© hace el pipeline.
    - QuÃ© protegerÃ¡ en el futuro.
    - QuÃ© te gustarÃ­a automatizar mÃ¡s adelante.

---

## âœ… Checklist de la clase

**IntegraciÃ³n Continua (CI)**:
- [ ]  Entiendes quÃ© es CI y para quÃ© sirve.
- [ ]  Has creado un pipeline funcional con GitHub Actions.
- [ ]  Tu repo ahora lanza los tests automÃ¡ticamente al hacer push o PR.

**OrquestaciÃ³n Multi-Agente** (40% AI integration):
- [ ]  Conoces los 4 agentes especializados para desarrollo de APIs.
- [ ]  Has aplicado el workflow de 5 fases (DiseÃ±o â†’ ImplementaciÃ³n â†’ ValidaciÃ³n REST â†’ Testing â†’ ValidaciÃ³n Final).
- [ ]  Has usado al menos 2 agentes educacionales en tu desarrollo.
- [ ]  Entiendes cuÃ¡ndo usar cada agente segÃºn la situaciÃ³n.
- [ ]  Has documentado tu experiencia con agentes en `notes.md`.

**DocumentaciÃ³n**:
- [ ]  Has documentado lo que aprendiste sobre CI/CD en `notes.md`.
- [ ]  Has documentado quÃ© agentes usaste y quÃ© feedback te dieron.
- [ ]  Has documentado cÃ³mo cambiÃ³ tu cÃ³digo gracias al feedback de agentes.

---

## ğŸŒ± QuÃ© sigue

En el prÃ³ximo mÃ³dulo, entramos de lleno en **Calidad y Seguridad**:

- Vamos a aÃ±adir seguridad real (validaciÃ³n, JWT, .envâ€¦).
- Fortalecer la cobertura de tests.
- **Auditar con IA** (nuevos agentes especializados en seguridad).
- Preparar el despliegue real.

Porque una API que no se rompe es genial.

Pero una API que **no te hackean** y **se despliega sola**... eso ya es otro nivel.

---

## ğŸ¯ Proyecto Final del MÃ³dulo 2: API Completa con Agentes

**Objetivo**: Desarrollar una API de tareas completa usando orquestaciÃ³n de agentes desde el diseÃ±o hasta el deployment.

### Requisitos TÃ©cnicos:
1. **Arquitectura limpia**: API â†’ Service â†’ Repository (validada por Clean Architecture Enforcer)
2. **Endpoints RESTful**: CRUD completo (validado por API Design Reviewer)
3. **ValidaciÃ³n completa**: Pydantic models (revisado por FastAPI Design Coach)
4. **Tests completos**: 80%+ coverage (estrategia de Test Coverage Strategist)
5. **CI/CD**: Pipeline de GitHub Actions que ejecute tests, linting, coverage

### Requisitos de Agentes (40% AI integration):
- **Documenta en `AGENTS_WORKFLOW.md`**:
  - QuÃ© agente usaste en cada fase
  - QuÃ© prompt le enviaste
  - QuÃ© feedback te dio
  - CÃ³mo cambiÃ³ tu cÃ³digo gracias a Ã©l
  - Tiempo ahorrado vs desarrollo manual

### Entregables:
1. **CÃ³digo**: API completa en carpeta `proyecto-final/`
2. **Tests**: Unit + Integration + API tests (80%+ coverage)
3. **CI/CD**: `.github/workflows/ci.yml` funcional
4. **DocumentaciÃ³n AI**: `AGENTS_WORKFLOW.md` completo
5. **ReflexiÃ³n**: `notes.md` sobre tu experiencia con agentes

### Criterios de EvaluaciÃ³n:
- âœ… **Arquitectura** (25%): Clean Architecture Enforcer valida sin violaciones
- âœ… **API Design** (25%): API Design Reviewer confirma REST compliance
- âœ… **Calidad** (25%): Tests pasan, coverage >80%, linting OK
- âœ… **AI Integration** (25%): Workflow multi-agente documentado, 40%+ del desarrollo asistido por agentes

---

Â¿Listo para construir con tu ejÃ©rcito de agentes especializados?

Haz el PR de esta clase y pasamos al **MÃ³dulo 3: Calidad y Seguridad**.

## Posibles errores

En nuestro caso, como estamos dividiendo cada clase en carpetas diferentes, nuestro CI daba problemas. Asi que directamente hemos modificado nuestro CI para que haga los test por carpeta de forma independiente.

En nuestro caso, en la clase 1 solo esta hecho lo que explicamos en esa clase, para que podais ir viendo como va cambiando el archivo y los test a medida que avanzamos. Esto me provocaba un problema de carpetas.

Si en tu caso estas copiando el repo tal cual, pon el ci asi:

```sql
name: CI - Tests por clase

on:
  push:
    branches: [main, dev]
  pull_request:
    branches: [main, dev]

jobs:
  test:
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        class_dir:
          - "Modulo 2 â€“ IngenierÃ­a y Arquitectura/Clase 2 - Principios SOLID y paradigmas de programacion"
          - "Modulo 2 â€“ IngenierÃ­a y Arquitectura/Clase 3 - Arquitectura limpia"
          - "Modulo 2 â€“ IngenierÃ­a y Arquitectura/Clase 4 - Open_Closed y Dependency Inversion"
          - "Modulo 2 â€“ IngenierÃ­a y Arquitectura/Clase 5 - Integracion y pruebas de arquitectura"
          - "Modulo 2 â€“ IngenierÃ­a y Arquitectura/Clase 6 - Integracion continua y control de calidad"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Pytest (tests)
        working-directory: ${{ matrix.class_dir }}
        run: |
          # Opcional: limpiar cachÃ©s por si vinieran del repo
          find . -type d -name "__pycache__" -exec rm -rf {} +
          find . -type f -name "*.pyc" -delete
          pytest -q

```

Si no es tu caso, deberian pasar los test como ya lo habiamos explicado.

Haz el PR de esta clase y pasamos al siguiente bloque.

