# Historial de Prompts - Clase 1

Este documento registra todos los prompts usados durante la clase, tanto exitosos como fallidos.

---

## ‚úÖ Prompts que FUNCIONARON bien

### Prompt #1: Versi√≥n Production-Ready

**Prompt**:
```
Crea una CLI de gesti√≥n de tareas en Python con las siguientes caracter√≠sticas:

**Requisitos funcionales**:
- Comando `agregar <texto>`: a√±ade tarea
- Comando `listar`: muestra todas las tareas
- Comando `completar <id>`: marca tarea como completada
- Persistencia en archivo JSON
- IDs autoincrementales

**Requisitos t√©cnicos**:
- Usar `argparse` para parsing de comandos
- Separar en funciones (dominio, persistencia, CLI)
- Manejo de errores (archivo corrupto, ID inexistente)
- Docstrings en todas las funciones
- Python 3.12

**Output esperado**:
- Un solo archivo `tareas_ia_completo.py` con todo el c√≥digo
- C√≥digo limpio y comentado
```

**Resultado**:
[Pega aqu√≠ lo que gener√≥ la IA]

**Por qu√© funcion√≥**:
- ‚úÖ Especific√≥ lenguaje y versi√≥n (Python 3.12)
- ‚úÖ Detall√≥ requisitos funcionales claros
- ‚úÖ Indic√≥ estructura t√©cnica (argparse, separaci√≥n de concerns)
- ‚úÖ Especific√≥ formato de output (un solo archivo)
- ‚úÖ Pidi√≥ docstrings (mejora legibilidad)

**Lo que aprend√≠**:
- [Escribe qu√© aprendiste de la respuesta de la IA]
- [¬øQu√© us√≥ la IA que no conoc√≠as?]

---

### Prompt #2: Refactoring con Single Responsibility

**Prompt**:
```
Refactoriza este c√≥digo Python siguiendo el principio de Single Responsibility:
- Extrae comandos a funciones separadas
- Crea una funci√≥n main()
- A√±ade docstrings a cada funci√≥n

C√≥digo:
[c√≥digo "feo" pegado aqu√≠]

Mant√©n el mismo comportamiento exacto.
```

**Resultado**:
[Pega aqu√≠ el c√≥digo refactorizado]

**Por qu√© funcion√≥**:
- ‚úÖ Especific√≥ el principio SOLID a aplicar (Single Responsibility)
- ‚úÖ Detall√≥ qu√© hacer (extraer funciones, crear main)
- ‚úÖ Constraint importante: "mant√©n el mismo comportamiento"
- ‚úÖ Pidi√≥ docstrings para mejor documentaci√≥n

**Lo que aprend√≠**:
- [Escribe qu√© aprendiste sobre refactoring]

---

### Prompt #3: Debugging Espec√≠fico

**Prompt**:
```
Tengo este c√≥digo Python que da error al ejecutarlo:

[c√≥digo con bugs pegado]

Error:
  File "tareas_bugs.py", line 8
    if comando = "listar":
               ^
SyntaxError: invalid syntax

¬øQu√© est√° mal y c√≥mo lo corrijo?
```

**Resultado**:
[Respuesta de la IA con explicaci√≥n]

**Por qu√© funcion√≥**:
- ‚úÖ Incluy√≥ c√≥digo completo
- ‚úÖ Incluy√≥ error exacto con traceback
- ‚úÖ Pregunta espec√≠fica ("qu√© est√° mal y c√≥mo corregirlo")
- ‚úÖ Contexto suficiente para que la IA entienda el problema

**Lo que aprend√≠**:
- [Qu√© bugs encontr√≥ la IA que no viste t√∫]

---

## ‚ùå Prompts que NO funcionaron bien

### Prompt Malo #1: Demasiado Vago

**Prompt**:
```
Crea una app de tareas
```

**Resultado**:
[Descripci√≥n del c√≥digo que gener√≥ - probablemente muy gen√©rico]

**Problema**:
- ‚ùå No especifica lenguaje (¬øPython? ¬øJavaScript? ¬øJava?)
- ‚ùå No especifica tipo de app (¬øCLI? ¬øWeb? ¬øM√≥vil?)
- ‚ùå No indica features espec√≠ficas
- ‚ùå No menciona persistencia o estructura

**C√≥mo mejorarlo**:
Usar el Prompt #1 de arriba con todos los detalles.

---

### Prompt Malo #2: "Mejorar" Sin Contexto

**Prompt**:
```
Mejora este c√≥digo

[pegar c√≥digo]
```

**Resultado**:
[La IA probablemente hizo cambios aleatorios]

**Problema**:
- ‚ùå "Mejorar" es subjetivo (¬øperformance? ¬ølegibilidad? ¬øfeatures?)
- ‚ùå No especifica qu√© principios seguir
- ‚ùå No indica constraints (mantener comportamiento, no a√±adir deps, etc.)

**C√≥mo mejorarlo**:
```
Refactoriza este c√≥digo siguiendo Single Responsibility Principle.
Extrae funciones para cada comando.
Mant√©n el mismo comportamiento exacto.
No uses dependencias externas.
```

---

### Prompt Malo #3: Sin C√≥digo Ni Error

**Prompt**:
```
Este c√≥digo no funciona, ayuda
```

**Resultado**:
[La IA no puede ayudar sin ver el c√≥digo]

**Problema**:
- ‚ùå No incluye el c√≥digo
- ‚ùå No incluye el error
- ‚ùå No especifica qu√© deber√≠a hacer vs qu√© hace

**C√≥mo mejorarlo**:
Usar el Prompt #3 de arriba con c√≥digo + error + comportamiento esperado.

---

### Prompt Malo #4: Pedir Demasiado

**Prompt**:
```
Crea una CLI de tareas con persistencia en PostgreSQL, autenticaci√≥n JWT,
API REST con FastAPI, frontend en React, tests con pytest, CI/CD con GitHub Actions,
deployment en AWS, monitoreo con Prometheus, y documentaci√≥n en Swagger.
```

**Resultado**:
[C√≥digo gen√©rico que no funciona o es incompleto]

**Problema**:
- ‚ùå Demasiadas tecnolog√≠as a la vez
- ‚ùå La IA no puede generar un proyecto completo as√≠
- ‚ùå Mejor dividir en pasos incrementales

**C√≥mo mejorarlo**:
Dividir en prompts separados:
1. Primero: CLI b√°sica con persistencia en archivo
2. Luego: Migrar persistencia a PostgreSQL
3. Luego: A√±adir tests
4. Luego: API REST con FastAPI
5. etc.

---

## üìù Lecciones sobre Prompt Engineering

### Principio 1: Especificidad > Generalidad

‚ùå "Crea una API"
‚úÖ "Crea una API REST con FastAPI para [caso de uso espec√≠fico]"

### Principio 2: Contexto es Rey

‚ùå "¬øC√≥mo testeo esto?" (sin c√≥digo)
‚úÖ "Tengo esta funci√≥n [c√≥digo]. Usa pytest para testear [caso espec√≠fico]"

### Principio 3: Formato de Output Claro

‚ùå "Explica SOLID"
‚úÖ "Explica los 5 principios SOLID usando: Nombre, Definici√≥n, Ejemplo en Python, Anti-patr√≥n com√∫n"

### Principio 4: Constraints Ayudan

‚ùå "Refactoriza esto"
‚úÖ "Refactoriza esto siguiendo SRP, sin cambiar comportamiento, solo stdlib de Python"

### Principio 5: Dividir y Conquistar

‚ùå "Crea app completa con backend, frontend, DB, deploy"
‚úÖ Dividir en 4 prompts separados, uno por componente

---

## üéØ Template de Prompt Efectivo (Copia y Pega)

```
**Rol**: [Dev Python senior / Experto en X / etc.]

**Tarea**: [Descripci√≥n clara de qu√© quieres que haga]

**Requisitos funcionales**:
- [Feature 1]
- [Feature 2]
- [Feature 3]

**Requisitos t√©cnicos**:
- [Tecnolog√≠a/framework espec√≠fico con versi√≥n]
- [Patr√≥n de dise√±o a seguir]
- [Constraints: sin dependencias, solo stdlib, etc.]

**Output esperado**:
- [Formato: archivo √∫nico, m√∫ltiples archivos, estructura espec√≠fica]
- [Estilo: con comments, con docstrings, con tests, etc.]

**C√≥digo base** (si aplica):
[Pegar c√≥digo existente]

**Comportamiento esperado** (si es debugging):
[Qu√© deber√≠a hacer vs qu√© hace]
```

---

## üìö Recursos para Mejorar Prompts

- M√≥dulo 0, Clase 5: Prompt Engineering Avanzado
- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Library](https://docs.anthropic.com/claude/prompt-library)

---

## üß™ Ejercicio: Experimenta con Prompts

**Desaf√≠o**: Intenta generar el mismo c√≥digo con 3 prompts de diferentes niveles de especificidad:
1. Prompt vago (malo)
2. Prompt mejorado (bueno)
3. Prompt muy espec√≠fico (excelente)

Compara los resultados y documenta qu√© cambi√≥.
