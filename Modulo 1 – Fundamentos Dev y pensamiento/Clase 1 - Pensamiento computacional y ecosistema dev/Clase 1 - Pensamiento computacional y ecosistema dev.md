# Modulo 1 - Fundamentos del desarrollo ‚Äì Pensamiento

Ya tienes hecha la **Clase 0 ‚Äì Introducci√≥n** (configuraci√≥n, Git, primer PR y merge). Ahora toca la **Clase 1 del M√≥dulo 1**: **Fundamentos del desarrollo ‚Äì Pensamiento computacional y ecosistema dev**.

Para que quede claro el salto:

- **Clase 0**: dejar tu entorno listo y entender el flujo Git b√°sico (repos, ramas, PRs, merge/rebase).
- **Clase 1**: empezar con lo que hace a un dev de verdad ‚Üí descomponer problemas (pensamiento computacional), usar bien la terminal y seguir practicando Git con un proyecto m√≠nimo.

Te propongo esta estructura para la segunda clase:

---

# Clase 1 ‚Äì Pensamiento computacional y ecosistema dev

### Concepto

Un dev no piensa en ‚Äúel programa entero‚Äù, sino en piezas peque√±as.

El **pensamiento computacional** es descomponer un problema grande en pasos simples que un ordenador pueda ejecutar:

- **Descomposici√≥n** ‚Üí dividir en partes.
- **Reconocimiento de patrones** ‚Üí detectar lo que se repite.
- **Abstracci√≥n** ‚Üí ignorar lo irrelevante.
- **Algoritmos** ‚Üí definir pasos concretos.

Ejemplo: ‚ÄúQuiero una app CLI que gestione tareas‚Äù

1. A√±adir tarea.
2. Listar tareas.
3. Marcar como completada.
4. Guardar en un archivo JSON.

Ya tenemos un esquema m√≠nimo para programar.

### Aplicaci√≥n manual

- Crea una rama feature/tareas-app
- Crea en tu repo una carpeta `Modulo1/cli-tareas` *(Si lo prefieres puedes crear un repo para la aplicaci√≥n e ir mejorandola a medida que avanzas el curso)*.

### 1. Pensamiento computacional aplicado al mini-proyecto

Queremos una **app de l√≠nea de comandos (CLI)** que gestione tareas.

Problema grande: *‚Äúquiero un gestor de tareas‚Äù*. (Esto es lo que pensar√≠a un muggle)

Lo bajamos a pasos peque√±os:

1. **Entrada** ‚Üí el usuario escribe un comando (`agregar`, `listar`, `completar`).
2. **Procesamiento** ‚Üí el programa interpreta qu√© comando es.
3. **Salida** ‚Üí el programa responde (mostrar lista, a√±adir algo, marcar hecho).

Hasta aqu√≠ ni hemos escrito c√≥digo, solo descompusimos el problema.

### 2. Manual (c√≥mo lo har√≠a un dev sin IA)

Primero pruebo el esqueleto m√°s simple posible:

- Si escribo `python tareas.py listar`, quiero que me diga ‚ÄúAqu√≠ se mostrar√≠an las tareas‚Äù.
- Si escribo `python tareas.py agregar`, quiero que me diga ‚ÄúAqu√≠ se agregar√≠a una tarea‚Äù.
- Si escribo `python tareas.py completar` , quiero que me diga ‚ÄúAqu√≠ se completar√≠a una tarea‚Äù.

Eso se hace con un programa que mire los **argumentos de la terminal**.

En Python, esos argumentos se leen con `sys.argv`, que es una lista con lo que escribiste despu√©s de `python`.

Por ejemplo:

```bash
python tareas.py listar

```

‚Üí `sys.argv` ser√° `["tareas.py", "listar"]`.

Con esa l√≥gica, el programa puede decidir qu√© hacer seg√∫n el segundo elemento.

### 3. C√≥digo m√≠nimo explicado

```python
import sys   # sys nos da acceso a los argumentos de la terminal

# Si el usuario no puso nada m√°s despu√©s de "python tareas.py"
# Si hay menos de dos argumentos (El primero es el nombre del programa):
if len(sys.argv) < 2:
    print("Uso: python tareas.py <comando>") # Imprimimos en pantalla el mensaje

# En caso contrario:
else:
		# Creamos la variable comando y metemos dentro el argumento.
    comando = sys.argv[1]  # el segundo argumento: listar, agregar, etc.
    
    # Ojo, es sys.argv[1] porque en python empezamos desde el 0, es decir,
    # el primer argumento ser√≠a el [0] = tareas.py
    # el segundo argumento ser√≠a el [1] = listar / agregar / completar

		# Si el comando es listar
    if comando == "listar":
        print("Aqu√≠ se mostrar√≠an las tareas") # Imprimimos el mensaje
    
    # Si es agregar
    elif comando == "agregar":
        print("Aqu√≠ se agregar√≠a una tarea") # Imprimimos el mensaje
    
    # si es completar
    elif comando == "completar":
		    print("Aqu√≠ se completar√≠a una tarea") # Imprimimos el mensaje
    
    # En caso contrario
    else:
        print("Comando no reconocido") # Avisamos del error

```

Con esto **no hacemos nada √∫til todav√≠a**, pero ya tenemos un esqueleto.

Es como construir primero el chasis de un coche antes de meterle motor.

---

## ü§ñ Python Manual vs AI-Assisted (30 min)

Ahora que tienes el esqueleto manual funcionando, es el momento perfecto para entender **cu√°ndo usar IA y cu√°ndo no**.

### El mismo problema, dos caminos

Imagina que te piden: *"Crea una CLI que gestione tareas con persistencia en JSON"*.

Puedes resolverlo de **dos formas completamente diferentes**:

#### Camino 1: Manual (lo que acabas de hacer)
1. Empiezas con `sys.argv` b√°sico
2. A√±ades condiciones `if/elif/else`
3. Entiendes **cada l√≠nea** que escribes
4. Cuando algo falla, sabes exactamente d√≥nde buscar
5. El c√≥digo es **tuyo**, lo construiste pieza a pieza

**Resultado**: C√≥digo simple, comprensible, pero b√°sico.

#### Camino 2: IA-Asistido (lo que veremos ahora)
1. Escribes un prompt estructurado
2. La IA genera c√≥digo completo con `argparse`, manejo de errores, timestamps, etc.
3. Ejecutas, funciona... pero **¬øentiendes todo lo que hace?**
4. Cuando algo falla, tienes que leer c√≥digo que NO escribiste
5. El c√≥digo es **del modelo**, t√∫ lo adaptaste

**Resultado**: C√≥digo robusto, production-ready, pero complejo.

---

### Tabla comparativa: Manual vs IA

| Aspecto               | Manual (sys.argv)                | IA-Asistido (argparse + features)    |
|----------------------|----------------------------------|--------------------------------------|
| **Velocidad**        | Lento (2-3 horas aprendiendo)    | R√°pido (5 minutos generando)        |
| **Comprensi√≥n**      | Alta (l√≠nea a l√≠nea)             | Media (necesitas leer y entender)    |
| **Calidad inicial**  | B√°sica (esqueleto m√≠nimo)        | Alta (production-ready)              |
| **Escalabilidad**    | Requiere refactor manual         | Ya incluye estructura escalable      |
| **Aprendizaje**      | Profundo (construyes m√∫sculo)    | Superficial (peligro de dependencia) |
| **Debugging**        | F√°cil (sabes qu√© hace cada l√≠nea)| Complejo (c√≥digo desconocido)        |
| **Mantenimiento**    | F√°cil (c√≥digo simple)            | Requiere entender arquitectura       |
| **Features extra**   | Solo lo que pediste              | IA a√±ade extras (¬ønecesarios?)       |

---

### ¬øCu√°ndo usar cada uno?

#### Usa el camino MANUAL cuando:
‚úÖ Est√°s **aprendiendo** un concepto nuevo (como ahora con CLI)
‚úÖ Es c√≥digo **cr√≠tico** (seguridad, l√≥gica de negocio compleja)
‚úÖ Necesitas **comprensi√≥n profunda** del comportamiento
‚úÖ El proyecto es **peque√±o** y simple
‚úÖ Quieres **control total** sobre cada decisi√≥n

**Ejemplo**: Est√°s aprendiendo c√≥mo funciona `sys.argv` ‚Üí hazlo manual.

#### Usa el camino IA-ASISTIDO cuando:
‚úÖ Ya conoces el concepto y quieres **ir r√°pido**
‚úÖ Necesitas **boilerplate** (c√≥digo repetitivo que ya has escrito mil veces)
‚úÖ Quieres **explorar** diferentes soluciones r√°pidamente
‚úÖ El c√≥digo es **no cr√≠tico** (utilidades, scripts de desarrollo)
‚úÖ Tienes la capacidad de **revisar y entender** lo que genera la IA

**Ejemplo**: Necesitas parsing de argumentos con `argparse` (ya lo conoces) ‚Üí usa IA.

---

### La regla de oro

**Nunca uses IA para algo que no entender√≠as si lo leyeras l√≠nea a l√≠nea.**

Si la IA genera c√≥digo que te suena a chino, **STOP**:
1. Vuelve al camino manual
2. Aprende el concepto b√°sico primero
3. Cuando lo domines, entonces usa IA para acelerarte

**Analog√≠a del chef**:
- **Manual** = aprender a cocinar desde cero (cortar, cocinar, sazonar)
- **IA** = usar un robot de cocina cuando ya sabes cocinar

El robot es genial **si sabes cocinar**. Si no, solo produces comida que no entiendes.

---

### üéØ Ejercicio Pr√°ctico: IA Primero, Manual Despu√©s (20 min)

Vamos a poner en pr√°ctica la comparaci√≥n manual vs IA con un ejercicio concreto.

#### Reto

Necesitamos una funci√≥n `validar_comando(comando)` que:
- Reciba un string (el comando del usuario)
- Devuelva `True` si el comando es v√°lido (`"listar"`, `"agregar"`, o `"completar"`)
- Devuelva `False` en caso contrario

#### Parte A: IA Primero (5 min)

1. **Abre tu IA favorita** (ChatGPT, Claude, Copilot, etc.)

2. **Usa este prompt** (c√≥pialo exactamente):
```
Crea una funci√≥n en Python llamada validar_comando que reciba un string
y devuelva True si est√° en ['listar', 'agregar', 'completar'],
False en caso contrario.

Solo la funci√≥n, sin explicaciones.
```

3. **Ejecuta el c√≥digo** que te genere en un archivo `validar_ia.py`:
```python
# Pega aqu√≠ lo que te gener√≥ la IA
```

4. **Pru√©bala**:
```bash
python
>>> from validar_ia import validar_comando
>>> validar_comando("listar")
True
>>> validar_comando("borrar")
False
```

5. **Reflexi√≥n** (escr√≠bela en un comment):
```python
# ¬øQu√© hizo la IA que no esperabas?
# ¬øUs√≥ alguna estructura de datos que no conoc√≠as?
# ¬øEl c√≥digo es legible para ti?
```

#### Parte B: Manual Despu√©s (10 min)

Ahora, **SIN MIRAR** la soluci√≥n de la IA, implementa t√∫ mismo la funci√≥n en `validar_manual.py`.

Pistas:
- Puedes usar `if/elif/else`
- Puedes usar `in` con una lista
- Puedes usar un set (si lo conoces)

```python
def validar_comando(comando):
    # Tu implementaci√≥n aqu√≠
    pass
```

**Prueba tu versi√≥n**:
```bash
python
>>> from validar_manual import validar_comando
>>> validar_comando("listar")
True
>>> validar_comando("borrar")
False
```

#### Parte C: Comparaci√≥n (5 min)

Ahora **s√≠**, compara ambas versiones:

1. **Abre ambos archivos** lado a lado
2. **Anota las diferencias**:
   - ¬øCu√°l es m√°s corta?
   - ¬øCu√°l es m√°s legible?
   - ¬øCu√°l manejar√≠a mejor edge cases (ej: `None`, espacios extra)?
   - ¬øCu√°l entiendes mejor?

3. **Aprendizaje clave**:
   - Si la IA us√≥ algo que NO entiendes ‚Üí an√≥talo y b√∫scalo
   - Si tu versi√≥n manual tiene bugs ‚Üí compara con la IA para aprender
   - **Lo ideal**: combinar lo mejor de ambas

**Ejemplo de reflexi√≥n**:
```python
# Mi versi√≥n: if/elif/else (3 l√≠neas, clara pero repetitiva)
# IA versi√≥n: comando in ['listar', 'agregar', 'completar'] (1 l√≠nea, Pythonic)
#
# Aprend√≠: el operador 'in' con listas es m√°s elegante que if/elif
# Decisi√≥n: adoptar√© la versi√≥n IA porque la entiendo Y es mejor
```

---

### 4. Aplicaci√≥n con IA

Una vez que este esqueleto corre, puedes pedirle a la IA que lo ampl√≠e.

Ejemplo de prompt:

```
Rol: Dev Python senior.
Tarea: Tengo un script CLI que recibe comandos agregar, listar y completar. Quiero que las tareas se guarden en un archivo JSON.
Formato: Dame el c√≥digo base limpio y con comentarios.
```

La IA te dar√° un c√≥digo m√°s gordo con lectura/escritura en JSON.

T√∫ decides si aceptar todo, o copiar solo lo que entiendes.

Luego revisas y refactorizas t√∫, aplicando lo que vimos en Git (rama `feature/cli-tareas`, commit, PR, merge).

---

## üêõ Debugging con IA (20 min)

Todos cometemos errores al programar. La diferencia est√° en c√≥mo los encontramos y solucionamos.

Vamos a comparar **debugging manual** vs **debugging con IA** para que entiendas cu√°ndo usar cada uno.

### Escenario: C√≥digo con bugs

Imagina que escribiste este c√≥digo y al ejecutarlo obtienes un error:

```python
import sys

if len(sys.argv) < 2:
    print("Uso: python tareas.py <comando>")
else:
    comando = sys.argv[1]

    if comando = "listar":  # üêõ BUG 1: = en vez de ==
        print("Aqu√≠ se mostrar√≠an las tareas")

    elif comando == "agregar":
        if len(sys.argv) < 3:
            print("Error: falta el texto de la tarea")
        else:
            tarea = sys.argv[2]
            print(f"Tarea agregada: {tarea"})  # üêõ BUG 2: falta cerrar f-string

    elif comando == "completar":
        if len(sys.argv) < 3:
            print("Error: falta el ID de la tarea")
        else:
            task_id = sys.argv[2]
            print(f"Tarea {task_id} completada")

    else:
        print("Comando no reconocido")
```

**Error al ejecutar**:
```
  File "tareas_bugs.py", line 8
    if comando = "listar":
               ^
SyntaxError: invalid syntax
```

---

### M√©todo 1: Debugging Manual (Sin IA) - 2-5 minutos

**Pasos**:
1. **Leer el mensaje de error**: `SyntaxError: invalid syntax` en l√≠nea 8
2. **Ir a la l√≠nea 8**: `if comando = "listar":`
3. **Analizar**: ¬øQu√© est√° mal? Ah, `=` es asignaci√≥n, necesito `==` para comparar
4. **Corregir** y volver a ejecutar

**Ventajas**:
‚úÖ Aprendes a leer errores (habilidad cr√≠tica)
‚úÖ Entrenas tu "ojo cl√≠nico" para detectar bugs
‚úÖ Memoria muscular: no cometer√°s el mismo error otra vez

**Desventajas**:
‚ùå Puede llevar m√°s tiempo si no sabes interpretar el error
‚ùå Si hay m√∫ltiples bugs, los descubres uno por uno

---

### M√©todo 2: Debugging con IA - 30 segundos

**Prompt efectivo**:
```
Tengo este c√≥digo Python que da error al ejecutarlo:

[pegar c√≥digo completo]

Error:
  File "tareas_bugs.py", line 8
    if comando = "listar":
               ^
SyntaxError: invalid syntax

¬øQu√© est√° mal y c√≥mo lo corrijo?
```

**Respuesta de IA** (ejemplo):
```
El error est√° en la l√≠nea 8. Usas = (asignaci√≥n) en vez de == (comparaci√≥n).

Correcci√≥n:
    if comando == "listar":

Adem√°s, detecto otro bug en la l√≠nea 14:
    print(f"Tarea agregada: {tarea"})
Falta cerrar la f-string correctamente:
    print(f"Tarea agregada: {tarea}")

C√≥digo corregido completo:
[c√≥digo sin errores]
```

**Ventajas**:
‚úÖ **Instant√°neo**: detecta TODOS los bugs a la vez
‚úÖ **Explica** el error (√∫til si no lo entend√≠as)
‚úÖ Te da el c√≥digo corregido

**Desventajas**:
‚ùå **Peligro de dependencia**: "la IA lo arregla, yo no aprendo"
‚ùå Pierdes pr√°ctica en leer errores
‚ùå Si usas IA siempre, no desarrollas debugging skills

---

### ¬øCu√°ndo usar cada m√©todo?

#### Debugging MANUAL cuando:
‚úÖ El error es simple y puedes entenderlo
‚úÖ Est√°s **aprendiendo** (como ahora)
‚úÖ Quieres entrenar debugging skills
‚úÖ El c√≥digo es tuyo y lo entiendes bien

#### Debugging IA cuando:
‚úÖ El error es cr√≠ptico y no sabes qu√© significa
‚úÖ Llevas >10 minutos atascado
‚úÖ El c√≥digo es ajeno (legacy code que no escribiste)
‚úÖ Quieres validar tu hip√≥tesis de qu√© est√° mal

---

### üéØ Ejercicio Pr√°ctico: Encuentra 3 Bugs

Crea un archivo `tareas_bugs.py` con el c√≥digo de arriba (con los 2 bugs).

**Desaf√≠o**:
1. **SIN IA** (5 min): Ejecuta el c√≥digo, lee el error, corr√≠gelo. ¬øCu√°ntos bugs encontraste?
2. **CON IA** (2 min): Ahora pasa el c√≥digo a la IA y pide que encuentre TODOS los bugs
3. **Compara**: ¬øEncontraste los mismos bugs? ¬øLa IA detect√≥ algo que se te escap√≥?

**Reflexi√≥n**:
```python
# Sin IA encontr√©: [escribe cu√°ntos]
# Con IA encontr√≥: [escribe cu√°ntos]
#
# Aprendizaje: [¬øQu√© bug no viste? ¬øPor qu√© la IA lo detect√≥?]
```

---

### Prompts Efectivos para Debugging

‚ùå **Prompts MALOS**:
- "Este c√≥digo no funciona" (sin c√≥digo, sin error)
- "Ayuda" (demasiado vago)
- "Hay un bug aqu√≠" (sin especificar d√≥nde ni qu√© hace)

‚úÖ **Prompts BUENOS**:
```
Tengo este c√≥digo Python [pegar c√≥digo].

Al ejecutar `python tareas.py listar` obtengo este error:
[pegar error completo con traceback]

¬øQu√© est√° mal y c√≥mo lo corrijo?
```

```
Este c√≥digo deber√≠a imprimir las tareas, pero imprime una lista vac√≠a siempre:
[pegar c√≥digo]

Datos de prueba: [explicar qu√© esperas vs qu√© obtienes]

¬øD√≥nde est√° el bug?
```

**Regla de oro**: Cuanto m√°s **contexto** des (c√≥digo + error + comportamiento esperado), mejor ayuda te dar√° la IA.

---

## ‚ôªÔ∏è Refactoring Asistido (20 min)

**Refactorizar** = mejorar el c√≥digo sin cambiar su comportamiento.

Es como reorganizar tu armario: la ropa es la misma, pero ahora est√° m√°s ordenada y encuentras las cosas m√°s r√°pido.

### Por qu√© refactorizar

El c√≥digo "feo" funciona, pero:
- ‚ùå Es dif√≠cil de leer
- ‚ùå Es dif√≠cil de modificar
- ‚ùå Tiene l√≥gica repetida
- ‚ùå Viola principios de c√≥digo limpio (como Single Responsibility)

Refactorizar convierte c√≥digo "que funciona" en c√≥digo "que funciona Y es mantenible".

---

### C√≥digo "feo" inicial

Este c√≥digo funciona, pero tiene problemas:

```python
import sys

if len(sys.argv) < 2:
    print("Uso: python tareas.py <comando>")
else:
    comando = sys.argv[1]

    if comando == "listar":
        print("=== LISTA DE TAREAS ===")
        print("[ ] 1. Estudiar Git")
        print("[ ] 2. Hacer ejercicio")
        print("[x] 3. Leer documentaci√≥n")

    elif comando == "agregar":
        if len(sys.argv) < 3:
            print("Error: falta el texto de la tarea")
        else:
            tarea = sys.argv[2]
            print(f"Tarea agregada: {tarea}")
            print("Total de tareas: 4")

    elif comando == "completar":
        if len(sys.argv) < 3:
            print("Error: falta el ID")
        else:
            task_id = sys.argv[2]
            print(f"Tarea {task_id} marcada como completada")
            print("¬°Buen trabajo!")

    else:
        print("Comando no reconocido")
```

**Problemas**:
1. Todo el c√≥digo est√° en el nivel principal (no hay funciones)
2. La l√≥gica de validaci√≥n se repite (`if len(sys.argv) < 3`)
3. Los mensajes est√°n mezclados con la l√≥gica
4. Imposible testear sin ejecutar el script completo

---

### Refactoring Manual Guiado (Paso a paso)

Vamos a mejorar esto **manualmente** primero para que entiendas el proceso.

#### Paso 1: Extraer funci√≥n de uso
```python
def mostrar_uso():
    """Muestra c√≥mo usar el programa"""
    print("Uso: python tareas.py <comando>")
```

#### Paso 2: Extraer funciones por comando
```python
def comando_listar():
    """Lista todas las tareas"""
    print("=== LISTA DE TAREAS ===")
    print("[ ] 1. Estudiar Git")
    print("[ ] 2. Hacer ejercicio")
    print("[x] 3. Leer documentaci√≥n")

def comando_agregar(tarea):
    """Agrega una nueva tarea"""
    print(f"Tarea agregada: {tarea}")
    print("Total de tareas: 4")

def comando_completar(task_id):
    """Marca una tarea como completada"""
    print(f"Tarea {task_id} marcada como completada")
    print("¬°Buen trabajo!")
```

#### Paso 3: Refactorizar el main
```python
import sys

def main():
    if len(sys.argv) < 2:
        mostrar_uso()
        return

    comando = sys.argv[1]

    if comando == "listar":
        comando_listar()

    elif comando == "agregar":
        if len(sys.argv) < 3:
            print("Error: falta el texto de la tarea")
        else:
            comando_agregar(sys.argv[2])

    elif comando == "completar":
        if len(sys.argv) < 3:
            print("Error: falta el ID")
        else:
            comando_completar(sys.argv[2])

    else:
        print("Comando no reconocido")

if __name__ == "__main__":
    main()
```

**Mejoras logradas**:
‚úÖ Cada funci√≥n tiene UNA responsabilidad (Single Responsibility Principle)
‚úÖ El c√≥digo principal es m√°s corto y legible
‚úÖ Ahora puedes testear cada funci√≥n por separado
‚úÖ A√±adir nuevos comandos es m√°s f√°cil

---

### Refactoring con IA (5 min)

Ahora veamos c√≥mo la IA har√≠a el refactoring.

**Prompt efectivo**:
```
Refactoriza este c√≥digo Python siguiendo el principio de Single Responsibility:
- Extrae comandos a funciones separadas
- Crea una funci√≥n main()
- A√±ade docstrings a cada funci√≥n

C√≥digo:
[pegar c√≥digo "feo"]

Mant√©n el mismo comportamiento exacto.
```

**Respuesta t√≠pica de IA**:
La IA generar√° algo similar a lo que hicimos manualmente, pero probablemente a√±ada extras:
- Mejor manejo de errores
- Constantes para comandos v√°lidos
- Posiblemente una funci√≥n `validar_argumentos()`
- Type hints en funciones

---

### ¬øCu√°ndo usar cada m√©todo?

#### Refactoring MANUAL cuando:
‚úÖ Est√°s **aprendiendo** patrones de dise√±o (como ahora)
‚úÖ El c√≥digo es simple y entiendes qu√© mejorar
‚úÖ Quieres practicar principios como SOLID
‚úÖ Es un refactor peque√±o (1-2 funciones)

#### Refactoring IA cuando:
‚úÖ El c√≥digo es **grande** y tedioso de refactorizar
‚úÖ Ya conoces el principio pero quieres ver **diferentes aproximaciones**
‚úÖ Quieres refactorizar c√≥digo legacy que no escribiste
‚úÖ Necesitas refactorizar m√∫ltiples archivos a la vez

---

### üéØ Ejercicio Pr√°ctico: Refactor Challenge

**Tu misi√≥n**: Refactoriza el c√≥digo "feo" de dos formas.

#### Parte A: Manual (10 min)
1. Copia el c√≥digo "feo" en `tareas_refactor_manual.py`
2. Aplica los 3 pasos del refactoring guiado
3. Ejecuta y verifica que funciona igual

#### Parte B: Con IA (5 min)
1. Pasa el c√≥digo "feo" original a la IA con el prompt de arriba
2. Guarda el resultado en `tareas_refactor_ia.py`
3. Ejecuta y verifica que funciona

#### Parte C: Comparaci√≥n (5 min)
1. **Compara ambas versiones**:
   - ¬øCu√°l tiene mejor estructura?
   - ¬øLa IA a√±adi√≥ algo que no pensaste?
   - ¬øHay algo de la versi√≥n IA que NO entiendes?

2. **Crea versi√≥n h√≠brida** (`tareas_refactor_hybrid.py`):
   - Toma lo mejor de tu versi√≥n manual
   - Adopta las mejoras de IA que entiendas
   - **Rechaza** lo que no entiendas o sea over-engineering

**Reflexi√≥n final**:
```python
# De mi versi√≥n manual us√©: [qu√© conservaste]
# De la versi√≥n IA adopt√©: [qu√© mejoras tomaste]
# De la versi√≥n IA rechac√©: [qu√© descartaste y por qu√©]
```

---

### Lecci√≥n Clave: La IA propone, t√∫ decides

**No copies c√≥digo de IA a ciegas.**

Proceso correcto:
1. IA genera refactoring
2. **T√∫ lo lees** l√≠nea a l√≠nea
3. **Entiendes** cada cambio
4. **Decides** qu√© adoptar
5. **Adaptas** a tu estilo/necesidades

La IA puede sugerir usar `argparse`, `dataclasses`, `enum`, `typing`... todo genial, pero si no entiendes esas herramientas, **no las uses todav√≠a**.

**Regla de oro**: Solo refactoriza hacia c√≥digo que **entiendes completamente**.

---

## üöÄ Proyecto Final: CLI App con y sin IA (60 min)

Este es el proyecto integrador de la clase, donde aplicar√°s TODO lo aprendido.

### Estructura del proyecto

Tu carpeta `cli-tareas/` debe tener esta estructura al final:

```
cli-tareas/
‚îú‚îÄ‚îÄ tareas.py                    # ‚úÖ Ya existe - Esqueleto manual b√°sico
‚îú‚îÄ‚îÄ tareas_bugs.py               # üêõ C√≥digo con bugs (ejercicio debugging)
‚îú‚îÄ‚îÄ tareas_refactor_antes.py     # ‚ôªÔ∏è C√≥digo "feo" (ejercicio refactoring)
‚îú‚îÄ‚îÄ tareas_manual_refactor.py    # ‚ôªÔ∏è Tu refactoring manual
‚îú‚îÄ‚îÄ tareas_ia_refactor.py        # ‚ôªÔ∏è Refactoring generado por IA
‚îú‚îÄ‚îÄ tareas_hybrid.py             # üéØ Versi√≥n h√≠brida (manual + IA, lo mejor de ambos)
‚îú‚îÄ‚îÄ COMPARACION.md               # üìù Tu reflexi√≥n sobre manual vs IA
‚îî‚îÄ‚îÄ prompts_usados.md            # üìù Historial de prompts (buenos y malos)
```

---

### Paso 1: Implementaci√≥n Manual (Ya hecho ‚úÖ)

Ya tienes `tareas.py` con el esqueleto b√°sico usando `sys.argv`.

---

### Paso 2: Debugging Challenge (10 min)

1. **Crea** `tareas_bugs.py` con el c√≥digo bugueado de la secci√≥n "Debugging con IA"
2. **Intenta** encontrar los bugs manualmente (5 min)
3. **Usa IA** para validar (2 min)
4. **Reflexiona** en el mismo archivo (3 min)

---

### Paso 3: Refactoring Challenge (20 min)

1. **Manual** (10 min):
   - Copia `tareas_refactor_antes.py` a `tareas_manual_refactor.py`
   - Refactoriza siguiendo los 3 pasos guiados
   - Ejecuta y verifica

2. **Con IA** (5 min):
   - Pasa `tareas_refactor_antes.py` a la IA con el prompt de refactoring
   - Guarda el resultado en `tareas_ia_refactor.py`
   - Ejecuta y verifica

3. **Versi√≥n h√≠brida** (5 min):
   - Crea `tareas_hybrid.py`
   - Combina lo mejor de ambas versiones
   - Solo incluye c√≥digo que entiendes

---

### Paso 4: Versi√≥n IA Avanzada (10 min)

Ahora, usa IA para crear una versi√≥n "production-ready" completa.

**Prompt efectivo** (gu√°rdalo en `prompts_usados.md`):

````markdown
# Prompts Usados

## Prompt 1: Versi√≥n Production-Ready

Crea una CLI de gesti√≥n de tareas en Python con las siguientes caracter√≠sticas:

**Requisitos funcionales**:
- Comando `agregar <texto>`: a√±ade tarea
- Comando `listar`: muestra todas las tareas
- Comando `completar <id>`: marca tarea como completada
- Persistencia en archivo JSON
- IDs autoincrementales

**Requisitos t√©cnicos**:
- Usar `argparse` para parsing de comandos
- Separar en funciones (dominio, persistencia, CLI)
- Manejo de errores (archivo corrupto, ID inexistente)
- Docstrings en todas las funciones
- Python 3.12

**Output esperado**:
- Un solo archivo `tareas_ia_completo.py` con todo el c√≥digo
- C√≥digo limpio y comentado

## Resultado:

[Aqu√≠ pegar√°s lo que gener√≥ la IA]

## Reflexi√≥n:

¬øQu√© gener√≥ la IA que no esperabas?
¬øHay algo que no entiendes?
¬øQu√© adoptar√≠as para tu versi√≥n h√≠brida?
````

---

### Paso 5: Documento de Comparaci√≥n (15 min)

Crea `COMPARACION.md` con este template:

````markdown
# Comparaci√≥n: Manual vs IA vs H√≠brido

## 1. Versi√≥n Manual (`tareas.py`)

**Ventajas**:
- [Escribe 2-3 ventajas que experimentaste]

**Desventajas**:
- [Escribe 2-3 desventajas]

**Lo que aprend√≠**:
- [Qu√© aprendiste haciendo esto manualmente]

---

## 2. Versi√≥n IA (`tareas_ia_completo.py`)

**Ventajas**:
- [Qu√© hizo la IA que fue impresionante]

**Desventajas**:
- [Qu√© gener√≥ que no necesitabas o no entend√≠as]

**Lo que me sorprendi√≥**:
- [Features inesperados que a√±adi√≥ la IA]

---

## 3. Versi√≥n H√≠brida (`tareas_hybrid.py`)

**De la versi√≥n manual conserv√©**:
- [Qu√© partes mantuviste de tu c√≥digo manual]

**De la versi√≥n IA adopt√©**:
- [Qu√© mejoras de la IA integraste]

**Decisiones de dise√±o**:
- [Por qu√© elegiste esta combinaci√≥n]

---

## 4. Reflexi√≥n Final

**¬øCu√°l usar√≠as en un proyecto real?**
- [Tu respuesta razonada]

**¬øCu√°ndo usar√≠as solo IA?**
- [Escenarios donde IA sola es suficiente]

**¬øCu√°ndo evitar√≠as la IA?**
- [Cu√°ndo es mejor ir 100% manual]

**Principal aprendizaje de esta clase**:
- [Tu mayor insight sobre desarrollo manual vs IA-asistido]
````

---

### Paso 6: Historial de Prompts (5 min)

Ya iniciaste `prompts_usados.md` en el Paso 4. Ahora a√±ade:

````markdown
## Prompts que NO funcionaron bien

### Prompt malo #1:
```
Crea una app de tareas
```

**Problema**: Demasiado vago, la IA no sabe qu√© framework, qu√© features, qu√© nivel de complejidad.

**Resultado**: C√≥digo gen√©rico que no sirve.

---

### Prompt malo #2:
```
Mejora este c√≥digo [pegar c√≥digo]
```

**Problema**: "Mejorar" es subjetivo. ¬øMejorar qu√©? ¬øPerformance? ¬øLegibilidad? ¬øFeatures?

**Resultado**: La IA hace cambios aleatorios que tal vez no quieres.

---

## Lecciones sobre Prompt Engineering

1. **Especificidad** > Generalidad
2. **Contexto** es cr√≠tico (lenguaje, versi√≥n, frameworks)
3. **Output claro**: especifica formato, estructura, qu√© incluir/excluir
4. **Constraints** ayudan: "solo usa stdlib", "m√°ximo 100 l√≠neas", "sin dependencias"
````

---

### Criterios de √âxito

Has completado el proyecto si tienes:
‚úÖ 7 archivos Python funcionando
‚úÖ `COMPARACION.md` con reflexi√≥n completa
‚úÖ `prompts_usados.md` con ejemplos buenos y malos
‚úÖ Al menos 3 versiones ejecutables (manual, IA, h√≠brida)
‚úÖ Commits organizados en Git (cada paso un commit)

---

### Git Workflow para este proyecto

```bash
# Paso 1: Rama de trabajo
git checkout -b feature/cli-tareas-completo

# Paso 2: Commits incrementales
git add cli-tareas/tareas_bugs.py
git commit -m "feat(M1-C1): a√±adir ejercicio debugging con bugs intencionales"

git add cli-tareas/tareas_manual_refactor.py
git commit -m "feat(M1-C1): refactorizar versi√≥n manual con funciones"

git add cli-tareas/tareas_ia_refactor.py
git commit -m "feat(M1-C1): a√±adir refactoring generado por IA"

git add cli-tareas/tareas_hybrid.py cli-tareas/COMPARACION.md
git commit -m "feat(M1-C1): crear versi√≥n h√≠brida y documento comparativo"

git add cli-tareas/prompts_usados.md
git commit -m "docs(M1-C1): documentar prompts usados y lecciones"

# Paso 3: Push y PR
git push origin feature/cli-tareas-completo
gh pr create --base dev --title "feat(M1-C1): Proyecto CLI con comparaci√≥n Manual vs IA"
```

---

üëâ **Pr√≥ximos pasos** (despu√©s del proyecto):

1. Revisa la documentaci√≥n de `argparse` (lo que us√≥ la IA)
2. Lee sobre el patr√≥n Repository (separar persistencia de l√≥gica)
3. Investiga c√≥mo hacer tests para CLIs en Python (pytest)

En la siguiente clase profundizaremos en estos conceptos, pero con base en lo que ya construiste aqu√≠.

---

## ¬°¬°¬° Nota importante !!!

Si ya has usado la IA alguna vez para programar, te dar√°s cuenta de varios aspectos:

- No hemos dicho que IA usar (spoiler: la que quieras)
- Estamos dando prompts muy gen√©ricos, lo sabemos

Esto lo hacemos para no robarte el aprendizaje.

Cuando construyamos nuestra **CLI de tareas**, lo vamos a formalizar con **historias de usuario (si no sabes lo que es, no te preocupes, lo explicaremos m√°s adelante)**:

Ejemplos de historias de usuario (para que lo veas por encima)

- *Como usuario quiero agregar tareas para no olvidarlas.*
- *Como usuario quiero listarlas para saber qu√© tengo pendiente.*
- *Como usuario quiero marcarlas como completadas para sentirme productivo.*

Ese formato de ‚Äú**Como‚Ä¶ quiero‚Ä¶ para‚Ä¶**‚Äù funciona de maravilla en proyectos de desarrollo, pero mejor a√∫n funciona con la IA.

Luego, para que el c√≥digo sea verificable, pasamos esas historias a **escenarios Gherkin (tambi√©n se explicar√° m√°s adelante)**:

```gherkin
Feature: Gesti√≥n de tareas

  Scenario: Agregar una nueva tarea
    Given no tengo tareas
    When agrego la tarea "Estudiar Git"
    Then la lista de tareas debe contener "Estudiar Git"

  Scenario: Listar tareas existentes
    Given tengo una tarea "Estudiar Git"
    When ejecuto listar
    Then debo ver "Estudiar Git" en la salida

  Scenario: Completar tareas existentes
    Given He terminado la tarea "Estudiar Git"
    When ejecuto completar
    Then debo ver "Estudiar Git" completada y sentirme productivo

```

Esto no es solo documentaci√≥n: sirve para automatizar tests con frameworks como **pytest-bdd** en Python o **cucumber** en otros lenguajes. (Si te suena a Chino, no te agobies)

---

### Y c√≥mo encaja la IA

Una vez que tienes historias + escenarios, los *prompts* cambian de ‚Äúdame un CLI‚Äù a:

```
Rol: Dev Python senior con experiencia en BDD.
Tarea: Implementa el c√≥digo m√≠nimo en Python para que este escenario Gherkin pase:
Given no tengo tareas
When agrego la tarea "Estudiar Git"
Then la lista de tareas debe contener "Estudiar Git"
Formato: C√≥digo en Python, con persistencia en un archivo JSON.
```

Ahora ya no es gen√©rico: el prompt tiene **contexto de usuario**, **escenario verificable**, y la IA no se inventa tanto.

---

## Historias de usuario y TDD

Lo que acabamos de ver con las **historias de usuario** y los **escenarios Gherkin** se conecta directamente con una pr√°ctica clave en desarrollo moderno: **TDD (Test Driven Development)**.

La idea de TDD es casi filos√≥fica:

1. **Escribes primero el test** que define c√≥mo deber√≠a comportarse tu programa (antes de tener c√≥digo real).
2. Luego escribes el **m√≠nimo c√≥digo necesario** para que ese test pase.
3. Finalmente, **refactorizas** para mejorar el c√≥digo, manteniendo todos los tests verdes.

Ese ciclo se suele resumir como:

- **Red** ‚Üí escribes un test que falla (porque a√∫n no hay implementaci√≥n).
- **Green** ‚Üí escribes lo justo para que pase.
- **Refactor** ‚Üí limpias el c√≥digo sin romper nada.

¬øD√≥nde entran las historias de usuario aqu√≠?

- La historia en lenguaje natural (*‚ÄúComo usuario quiero agregar tareas para no olvidarlas‚Äù*) nos da el **qu√©**.
- El escenario Gherkin (*‚ÄúWhen agrego la tarea X, Then deber√≠a estar en la lista‚Äù*) nos da un **test verificable**.
- Ese test se convierte en la primera pieza del ciclo TDD.

As√≠, el camino es natural:

Historias de usuario ‚Üí Escenarios Gherkin ‚Üí Tests ‚Üí C√≥digo m√≠nimo ‚Üí Refactor.

No lo vamos a aplicar todav√≠a (porque primero necesitas dominar el esqueleto y Git), pero ya sabes por qu√© tanto bombo con Gherkin: no es solo ‚Äúdocumentar bonito‚Äù, es **pensar en el comportamiento desde el principio**.


# Resultado del ejercicio

Vale, si has hecho lo que te he pedido y le has preguntado a la IA, te habr√° devuelto un resultado parecido al que hay en 'cli-tareas/notes.md'

Buen√≠simo. Justo esto es lo que quer√≠a que vieras: la diferencia entre un **esqueleto m√≠nimo hecho a mano** y un **c√≥digo gordo ‚Äúproduction ready‚Äù que la IA puede escupir en segundos**.

F√≠jate en varios detalles de la respuesta:

- **Usa `argparse`** ‚Üí en lugar de `sys.argv` crudo, te da parsing limpio con subcomandos (`agregar`, `listar`, `completar`). Esto ya es un salto de nivel: m√°s ordenado, m√°s escalable.

- **Persistencia JSON** ‚Üí la IA monta lectura/escritura at√≥mica, ids autoincrementales, manejo de errores de archivo corrupto‚Ä¶ bastante m√°s de lo que pedir√≠a un profe en una primera pr√°ctica.

- **Capas separadas**:
    - funciones de dominio (`op_agregar`, `op_listar`, `op_completar`),
    - funciones de persistencia (`cargar_tareas`, `guardar_tareas`),
    - CLI (`argparse`) como capa externa.
        
        Eso ya es arquitectura limpia en miniatura.
        
- **Extras**: salida en formato humano o JSON, timestamps ISO, mensajes de error consistentes. Es un ejemplo de c√≥mo la IA mete features ‚Äúde m√°s‚Äù.

---

### Lo que quiero que saques de aqu√≠

1. **Tu versi√≥n manual** ‚Üí te da el m√∫sculo, entiendes `sys.argv`, condiciones b√°sicas y flujo m√≠nimo.
2. **Versi√≥n IA** ‚Üí te ense√±a hacia d√≥nde puedes llevarlo, pero si la usas *sin haber pasado por lo manual*, solo te vuelves dependiente.

Esto es justo el contraste que vamos a cultivar todo el m√°ster:

- T√∫ aprendes el *camino largo* (manual, sencillo, entendible).
- La IA te da el *atajo brutal* (argparse, persistencia robusta).
- Luego t√∫ decides qu√© adoptar y qu√© no.

---

### Siguiente paso

No tires todav√≠a con todo este mamotreto. Haz tu rama `feature/cli-tareas` con el **esqueleto simple**.

Despu√©s, crea otra rama (`feature/cli-json`) y ah√≠ ya pruebas el c√≥digo de la IA, lo ejecutas, ves c√≥mo se comporta, y vas entendiendo qu√© partes puedes simplificar.

As√≠ terminas con **dos PRs distintos**:

- uno con lo b√°sico,
- otro con lo ‚ÄúIA pro‚Äù.

Y en paralelo, preparamos las **historias de usuario + escenarios Gherkin** para empezar a ligar esto con **TDD**.