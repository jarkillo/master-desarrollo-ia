# Clase 6.5 - Claude Agent SDK: Building Professional Agents

**MÃ³dulo 4 - Infraestructura y Cloud**

**DuraciÃ³n estimada**: 6-8 horas

---

## Ãndice

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Objetivos de aprendizaje](#objetivos-de-aprendizaje)
3. [Conceptos clave](#conceptos-clave)
4. [Arquitectura del SDK](#arquitectura-del-sdk)
5. [Ejercicios prÃ¡cticos](#ejercicios-prÃ¡cticos)
6. [Proyecto final](#proyecto-final)
7. [Recursos adicionales](#recursos-adicionales)

---

## IntroducciÃ³n

Esta clase profundiza en el **Claude Agent SDK** de Anthropic, la herramienta oficial para construir agentes autÃ³nomos profesionales. DespuÃ©s de haber explorado LangChain en la Clase 6, ahora veremos cÃ³mo Anthropic diseÃ±a agentes desde el punto de vista del creador del modelo.

### Â¿Por quÃ© Claude Agent SDK?

**LangChain vs Claude Agent SDK**:
- **LangChain**: Framework versÃ¡til, multi-modelo, rico ecosistema de integraciones
- **Claude Agent SDK**: DiseÃ±ado especÃ­ficamente para Claude, optimizado para sus capacidades Ãºnicas, control fino del feedback loop

**CuÃ¡ndo usar cada uno**:
- **LangChain**: Proyectos multi-modelo, necesitas cambiar entre providers, ecosistema rico de herramientas
- **Claude Agent SDK**: MÃ¡ximo rendimiento con Claude, control preciso del loop de agente, debugging avanzado

### FilosofÃ­a del SDK

El SDK implementa el **feedback loop fundamental** de los agentes:

```
Gather Context â†’ Take Action â†’ Verify Work â†’ Repeat
```

Este ciclo iterativo permite a los agentes refinar sus salidas y detectar errores antes de que se acumulen.

---

## Objetivos de aprendizaje

Al finalizar esta clase, podrÃ¡s:

1. âœ… Entender la arquitectura del Claude Agent SDK
2. âœ… Implementar loops de control y flujo en agentes
3. âœ… DiseÃ±ar herramientas (tools) efectivas para agentes
4. âœ… Manejar errores y lÃ³gica de reintentos
5. âœ… Gestionar estado en agentes complejos
6. âœ… Debuggear agentes usando tÃ©cnicas profesionales
7. âœ… Comparar LangChain y Claude SDK segÃºn contexto
8. âœ… Construir un agente de desarrollo autÃ³nomo

---

## Conceptos clave

### 1. Context Gathering (RecopilaciÃ³n de contexto)

#### Agentic Search & File Systems

El sistema de archivos como **almacenamiento estructurado de informaciÃ³n**. Los agentes usan comandos bash (`grep`, `tail`, `find`) para cargar datos relevantes de forma inteligente.

**AnalogÃ­a**: El file system es como una biblioteca organizada. El agente es un investigador que sabe quÃ© estante revisar segÃºn la pregunta.

```python
# Ejemplo: Agente busca errores en logs
agent.run_bash("grep 'ERROR' logs/*.log | tail -20")
```

**Ventaja**: La estructura de carpetas es "una forma de context engineering" - organiza informaciÃ³n para que el agente la encuentre fÃ¡cilmente.

#### Semantic Search

BÃºsqueda por similitud vectorial (embeddings). MÃ¡s rÃ¡pida que agentic search, pero sacrifica precisiÃ³n y transparencia.

**RecomendaciÃ³n**: Empieza con agentic search, aÃ±ade semantic search solo si el rendimiento lo requiere.

#### Subagents (Sub-agentes)

Contextos de ejecuciÃ³n aislados que permiten:
- **ParalelizaciÃ³n**: MÃºltiples tareas simultÃ¡neas
- **GestiÃ³n de contexto**: CompartimentaciÃ³n de informaciÃ³n

**Ejemplo**: Un agente principal delega subtareas (buscar en docs, analizar cÃ³digo, ejecutar tests) a subagentes especializados.

#### Compaction (CompactaciÃ³n)

ResÃºmenes automÃ¡ticos de conversaciones para evitar agotamiento del contexto durante ejecuciones largas.

**AnalogÃ­a**: Como tomar notas de una reuniÃ³n larga - guardas lo importante, descarta detalles innecesarios.

---

### 2. Action Execution (EjecuciÃ³n de acciones)

#### Tool Design (DiseÃ±o de herramientas)

Las herramientas (tools) son **los bloques fundamentales de ejecuciÃ³n**. Aparecen prominentemente en el contexto de Claude, por lo que la selecciÃ³n estratÃ©gica de tools es crÃ­tica.

**Principios de diseÃ±o**:
- âœ… **EspecÃ­ficas**: Una tool = una funciÃ³n clara
- âœ… **Bien documentadas**: Descripciones claras para que Claude entienda cuÃ¡ndo usarlas
- âœ… **Idempotentes**: Llamadas repetidas = mismo resultado
- âœ… **Con validaciÃ³n**: Verificar inputs antes de ejecutar

#### Bash & Scripts

Flexibilidad general para tareas variadas: conversiÃ³n de PDFs, bÃºsquedas web, manipulaciÃ³n de archivos.

**Ejemplo**:
```python
# Tool para buscar en StackOverflow
bash_tool = BashTool(
    command="curl -s 'https://api.stackexchange.com/2.3/search?order=desc&sort=activity&intitle={query}&site=stackoverflow'"
)
```

#### Code Generation (GeneraciÃ³n de cÃ³digo)

**"El cÃ³digo es preciso, componible e infinitamente reutilizable"**. Ideal para operaciones complejas y creaciÃ³n de archivos (hojas de cÃ¡lculo, presentaciones, documentos).

**Ejemplo**: Un agente genera cÃ³digo Python para procesar datos, en lugar de hacerlo paso a paso con tools.

#### Model Context Protocol (MCP)

Integraciones estandarizadas con autenticaciÃ³n automÃ¡tica: Slack, GitHub, Asana. Sin gestiÃ³n manual de OAuth.

**Ventaja**: Plug-and-play con servicios externos sin implementar flujos de autenticaciÃ³n.

---

### 3. Verification & Improvement (VerificaciÃ³n y mejora)

#### Rules-Based Feedback

Feedback basado en reglas definidas. Ejemplo: linting de cÃ³digo.

**Ejemplo**: TypeScript linting proporciona mÃ¡s capas de validaciÃ³n que JavaScript.

```python
# DespuÃ©s de generar cÃ³digo, ejecutar linter
result = agent.execute(generate_code_task)
lint_result = agent.run_bash(f"ruff check {result.output_file}")
if lint_result.errors:
    agent.retry_with_feedback(lint_result.errors)
```

#### Visual Feedback

Screenshots para refinamiento iterativo de contenido UI. Verifica layout, estilos, jerarquÃ­a, responsividad.

**AnalogÃ­a**: Como un diseÃ±ador que revisa mockups - ve el resultado, ajusta, ve de nuevo.

#### LLM-as-Judge

EvaluaciÃ³n de un modelo secundario sobre criterios difusos. Sacrifica latencia por ganancias marginales de rendimiento.

**Ejemplo**: Evaluar la "calidad" de un texto generado usando otro LLM como juez.

---

### 4. Testing & Iteration

**Enfoques de evaluaciÃ³n**:
- Â¿El agente malinterpreta por falta de informaciÃ³n?
- Â¿Falla repetidamente en tareas especÃ­ficas?
- Â¿Tiene problemas corrigiendo errores?
- Â¿VarÃ­a el rendimiento al aÃ±adir features?

**PrÃ¡ctica recomendada**: Test sets representativos basados en uso real para mejora continua.

---

## Arquitectura del SDK

### Componentes principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Claude Agent SDK                  â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Agent     â”‚â—„â”€â”€â”€â”€â–ºâ”‚ Tool Manager â”‚     â”‚
â”‚  â”‚  Loop      â”‚      â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                     â”‚             â”‚
â”‚        â”‚                     â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Context   â”‚      â”‚ Verification â”‚     â”‚
â”‚  â”‚  Manager   â”‚      â”‚  Engine      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                     â”‚             â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                   â”‚                        â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚            â”‚    State     â”‚                â”‚
â”‚            â”‚  Management  â”‚                â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### El Agent Loop

```python
while not task_complete:
    # 1. Gather Context
    context = context_manager.gather()

    # 2. Take Action
    action = agent.decide_action(context)
    result = tool_manager.execute(action)

    # 3. Verify Work
    is_valid = verification_engine.check(result)

    if not is_valid:
        # 4. Iterate with feedback
        context_manager.add_feedback(verification_engine.errors)
        continue

    task_complete = True
```

---

## Ejercicios prÃ¡cticos

### Ejercicio 1: Primer agente simple con SDK
**Archivo**: `ejemplos/01_agente_simple.py`

Construye un agente que responda preguntas sobre un repositorio de cÃ³digo usando agentic search.

**Conceptos**: Context gathering, bash tools, feedback loop bÃ¡sico

---

### Ejercicio 2: Loops y control de flujo
**Archivo**: `ejemplos/02_control_flujo.py`

Implementa un agente con retry logic y manejo de estados (pendiente, en progreso, completado, fallido).

**Conceptos**: State management, error handling, iteraciÃ³n controlada

---

### Ejercicio 3: Tool calling avanzado
**Archivo**: `ejemplos/03_tools_avanzadas.py`

DiseÃ±a tools personalizadas con validaciÃ³n, idempotencia y logging.

**Conceptos**: Tool design, best practices, debugging

---

### Ejercicio 4: Subagentes y paralelizaciÃ³n
**Archivo**: `ejemplos/04_subagentes.py`

Crea un agente principal que coordina subagentes especializados (bÃºsqueda, anÃ¡lisis, ejecuciÃ³n).

**Conceptos**: Subagents, paralelizaciÃ³n, context management

---

## Proyecto final

### Agente de desarrollo autÃ³nomo

**DescripciÃ³n**: Construye un agente que automatiza tareas de desarrollo como:
- Analizar issues en GitHub
- Buscar cÃ³digo relevante en el repositorio
- Generar fix basado en patrones existentes
- Ejecutar tests y validar
- Crear Pull Request con los cambios

**Archivo**: `proyecto_final/agente_dev_autonomo.py`

**Requisitos**:
1. âœ… Context gathering desde GitHub API y file system
2. âœ… Tools personalizadas (git, pytest, code generation)
3. âœ… Verification engine con tests y linting
4. âœ… Retry logic para errores comunes
5. âœ… Logging detallado para debugging

**Acceptance criteria**:
- El agente resuelve al menos 3 tipos de issues simples (typos, imports faltantes, tests bÃ¡sicos)
- Ejecuta tests antes de crear PR
- Maneja errores comunes (tests fallan, linter falla)
- Genera logs claros del proceso

---

## Claude Agent SDK vs LangChain

| Aspecto | Claude Agent SDK | LangChain |
|---------|------------------|-----------|
| **EspecializaciÃ³n** | Claude-only, optimizado | Multi-modelo |
| **Control del loop** | Muy fino | AbstracciÃ³n mÃ¡s alta |
| **Debugging** | Tools especÃ­ficas | Callbacks generales |
| **Curva aprendizaje** | Moderada | MÃ¡s empinada |
| **Ecosistema** | Oficial Anthropic | Comunidad enorme |
| **Mejor para** | MÃ¡ximo rendimiento Claude | Flexibilidad, multi-modelo |

**RecomendaciÃ³n prÃ¡ctica**:
- ğŸ† **Prototipado rÃ¡pido**: LangChain
- ğŸ† **ProducciÃ³n con Claude**: Claude Agent SDK
- ğŸ† **Multi-modelo**: LangChain
- ğŸ† **Control fino**: Claude Agent SDK

---

## Recursos adicionales

### DocumentaciÃ³n oficial
- [Building Agents with Claude Agent SDK](https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk) (artÃ­culo base)
- [Anthropic Documentation](https://docs.anthropic.com/)
- [Tool Use Guide](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)

### Comparaciones
- [LangChain vs Custom Agent Loops](https://blog.langchain.dev/when-to-use-langchain/)
- [Agent Architectures Compared](https://www.anthropic.com/research/agent-architectures)

### Debugging
- [Debugging Claude Agents](https://docs.anthropic.com/en/docs/build-with-claude/debugging)
- [Prompt Engineering for Agents](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering)

---

## PrÃ³ximos pasos

DespuÃ©s de esta clase:
1. **Clase 6.6**: Context Engineering (cÃ³mo diseÃ±ar contexto efectivo para agentes)
2. **Clase 6.7**: Writing Tools for AI Agents (patrones avanzados de tool design)
3. **MÃ³dulo 5**: Full-Stack + Agent Orchestration Mastery

---

## Glosario

- **Agentic Search**: BÃºsqueda donde el agente decide quÃ© datos cargar usando herramientas
- **Compaction**: Resumen automÃ¡tico de conversaciones largas para gestiÃ³n de contexto
- **Feedback Loop**: Ciclo de gather context â†’ action â†’ verify â†’ iterate
- **MCP (Model Context Protocol)**: Protocolo estÃ¡ndar para integraciones con autenticaciÃ³n
- **Subagent**: Contexto de ejecuciÃ³n aislado para subtareas especializadas
- **Tool**: FunciÃ³n que el agente puede invocar (bash, API calls, code execution)
- **Verification Engine**: Sistema que valida las salidas del agente antes de continuar

---

**Tiempo estimado**: 6-8 horas (2 horas teorÃ­a, 3 horas ejercicios, 3 horas proyecto final)

**Nivel**: Avanzado (requiere MÃ³dulo 4 Clase 6 - LangChain)
