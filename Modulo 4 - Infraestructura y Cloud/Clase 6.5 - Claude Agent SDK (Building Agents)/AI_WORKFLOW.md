# AI Workflow - Clase 6.5: Claude Agent SDK

**Objetivo**: Integraci√≥n IA como herramienta central de aprendizaje (60%+ del contenido)

Esta clase ES SOBRE IA - el Claude Agent SDK. Por lo tanto, el 100% del contenido t√©cnico involucra IA, y la integraci√≥n IA est√° en el n√∫cleo de cada ejercicio.

---

## üéØ Resumen de integraci√≥n IA

| Componente | % IA | Descripci√≥n |
|------------|------|-------------|
| **Teor√≠a** | 100% | Claude Agent SDK, arquitectura de agentes, feedback loop |
| **Ejercicios** | 100% | Todos usan Anthropic API para crear agentes |
| **Proyecto final** | 100% | Agente aut√≥nomo de desarrollo con Claude |
| **Debugging** | 80% | IA para an√°lisis de logs + debugging manual |

**Total: ~95% integraci√≥n IA** (supera el 60% requerido)

---

## üìö Parte 1: Fundamentos de agentes con IA (100% IA)

### Conceptos a aprender CON IA

1. **Feedback loop fundamental**
   ```
   Gather Context ‚Üí Take Action ‚Üí Verify Work ‚Üí Repeat
   ```
   - **Prompt para entender**: "Explica el feedback loop de agentes con analog√≠a de desarrollo de software"
   - **IA genera**: Ejemplos de bucles en debugging, testing, refactoring

2. **Context gathering strategies**
   - Agentic search vs Semantic search
   - **Ejercicio IA**: Pedir a Claude que compare las dos estrategias con tabla de trade-offs
   - **Prompt**: "¬øCu√°ndo usar agentic search vs semantic search en agentes? Dame casos de uso espec√≠ficos"

3. **Tool design patterns**
   - **IA explica**: Best practices de tool design
   - **Prompt**: "Dame 5 principios de dise√±o de tools para agentes Claude, con ejemplos de buen y mal dise√±o"

---

## üíª Parte 2: Ejercicios pr√°cticos (100% IA)

Todos los ejercicios requieren usar la Anthropic API directamente.

### Ejercicio 1: Primer agente simple (archivo: `ejemplos/01_agente_simple.py`)

**Objetivo**: Agente que explora repositorio usando bash tools

**Workflow con IA**:

1. **Dise√±o del agente** (IA-assisted)
   ```
   Prompt a Claude Code:
   "Ay√∫dame a dise√±ar la estructura de un agente simple que explore
   repositorios con comandos bash. ¬øQu√© clase base necesito? ¬øQu√©
   m√©todos son esenciales?"
   ```

2. **Implementaci√≥n** (100% IA en runtime)
   - El agente usa Claude API para decidir qu√© comandos bash ejecutar
   - Implementa feedback loop completo
   - IA analiza outputs y decide pr√≥ximos pasos

3. **Debugging con IA**
   ```
   Prompt:
   "Este agente ejecuta 'ls' repetidamente sin avanzar. Analiza el log
   y sugiere qu√© est√° fallando en mi implementaci√≥n del feedback loop"
   ```

**Ejercicio extendido**:
- Usa IA para generar tests del agente
- Pide a Claude que optimice la estrategia de b√∫squeda del agente

---

### Ejercicio 2: State management y retry logic (archivo: `ejemplos/02_control_flujo.py`)

**Objetivo**: Agente con estados, retry logic y verificaci√≥n con LLM-as-judge

**Workflow con IA**:

1. **State machine design** (IA-assisted)
   ```
   Prompt:
   "Dise√±a una state machine para un agente de desarrollo con estados:
   pending, in_progress, completed, failed, retrying.
   ¬øQu√© transiciones son v√°lidas? Genera un diagrama en Mermaid."
   ```

2. **Verificaci√≥n con LLM-as-judge** (100% IA)
   - El agente usa Claude para validar sus propios resultados
   - Pattern: Un LLM genera, otro LLM verifica
   - **Prompt para verificador**:
     ```python
     f"Verifica si este resultado cumple la tarea: {task_description}
     Resultado: {result}
     Responde V√ÅLIDO o INV√ÅLIDO con raz√≥n."
     ```

3. **Retry logic inteligente** (IA-driven)
   - Backoff exponencial cl√°sico
   - Pero el agente usa IA para analizar *por qu√©* fall√≥
   - Ajusta estrategia en cada retry

**Ejercicio con IA**:
```
Prompt a Claude Code:
"El agente est√° en retry loop infinito. Analiza este log y sugiere
c√≥mo mejorar la l√≥gica de retry para detectar fallos irrecuperables."
```

---

### Ejercicio 3: Tool design avanzado (archivo: `ejemplos/03_tools_avanzadas.py`)

**Objetivo**: Dise√±ar tools profesionales con validaci√≥n, logging, idempotencia

**Workflow con IA**:

1. **Dise√±o de tools** (IA-assisted)
   ```
   Prompt:
   "Necesito dise√±ar una tool para ejecutar pytest. Genera el schema
   Anthropic con:
   - Input parameters (path, verbose)
   - Descripci√≥n clara para que Claude entienda cu√°ndo usarla
   - Ejemplo de input_schema completo"
   ```

2. **Validaci√≥n con IA**
   - Pide a Claude Code que revise tus tools
   - **Prompt**: "Revisa esta tool design. ¬øCumple con: espec√≠fica, bien documentada, idempotente, con validaci√≥n?"

3. **Debugging de tool calls**
   - Usa IA para analizar por qu√© Claude elige (o no) una tool
   - **Prompt**: "Claude no est√° usando mi GitStatusTool. Analiza la descripci√≥n y sugiere mejoras"

**Ejercicio avanzado**:
- Pide a IA que genere 3 tools m√°s para el agente
- Usa IA para generar tests de las tools

---

### Ejercicio 4: Subagentes y paralelizaci√≥n (archivo: `ejemplos/04_subagentes.py`)

**Objetivo**: Agente maestro que coordina subagentes especializados

**Workflow con IA**:

1. **Arquitectura de subagentes** (IA-assisted)
   ```
   Prompt:
   "Dise√±a una arquitectura de agente maestro + 3 subagentes para
   analizar proyectos Python. ¬øQu√© responsabilidad tiene cada uno?
   ¬øC√≥mo se comunican? ¬øQu√© retorna cada subagente al maestro?"
   ```

2. **Specialization con system prompts** (100% IA)
   - Cada subagente tiene system prompt √∫nico
   - IA para generar system prompts efectivos
   - **Ejemplo**: SearchAgent vs AnalysisAgent vs TestAgent

3. **Synthesis con IA** (100% IA)
   - Agente maestro usa Claude para sintetizar resultados de subagentes
   - Pattern: Multiple LLM calls ‚Üí Single synthesis call

**Ejercicio con IA**:
```
Prompt:
"Tengo 3 subagentes con outputs largos. ¬øC√≥mo dise√±o el prompt de
s√≠ntesis para que el maestro genere un resumen ejecutivo de m√°ximo
10 l√≠neas sin perder informaci√≥n cr√≠tica?"
```

---

## üèÜ Parte 3: Proyecto final - Agente aut√≥nomo (100% IA)

**Archivo**: `proyecto_final/agente_dev_autonomo.py`

### Workflow completo con IA

#### 1. An√°lisis de issue (IA)
```python
# IA clasifica tipo de issue
issue_type = agent._classify_issue(issue)
# Prompt: "Clasifica este issue en: typo, missing_import, simple_test, ..."
```

#### 2. Context gathering (IA + agentic search)
```python
# IA decide qu√© comandos bash ejecutar para encontrar c√≥digo relevante
context = agent._gather_context(issue)
# Prompt: "¬øQu√© archivos debo revisar para este issue? Sugiere comandos bash."
```

#### 3. Generaci√≥n de fix (IA)
```python
# IA genera el c√≥digo del fix completo
fix_code = agent._generate_fix(issue, context)
# Prompt: "Genera fix para este issue. Formato JSON con archivos completos."
```

#### 4. Verificaci√≥n (IA + herramientas)
```python
# Verificaci√≥n h√≠brida:
# - Tests: pytest (tool tradicional)
# - Linting: ruff (tool tradicional)
# - Validaci√≥n sem√°ntica: Claude (IA)

if not tests_passed:
    # IA analiza por qu√© fallaron
    analysis = agent._analyze_test_failure(test_output)
    # Retry con feedback de IA
```

#### 5. PR description (IA)
```python
# IA genera descripci√≥n profesional del PR
pr_description = agent._generate_pr_description(issue, files_modified)
# Incluye: changes, verification, related issue
```

### Ejercicios con IA para el proyecto

1. **Prompt engineering para fix generation**
   ```
   Experimento:
   1. Genera un fix con prompt b√°sico
   2. Genera el mismo fix con prompt detallado (incluye: context, retry guidance, format)
   3. Compara calidad de outputs

   Pregunta: ¬øQu√© elementos del prompt m√°s afectan la calidad del fix?
   ```

2. **Optimizaci√≥n de context gathering**
   ```
   Usa IA para analizar:
   - ¬øCu√°ntos comandos bash se ejecutan en promedio?
   - ¬øHay comandos redundantes?
   - ¬øSe puede predecir qu√© archivos revisar sin ejecutar comandos?

   Prompt a Claude Code:
   "Analiza este log de comandos bash. ¬øC√≥mo optimizar√≠as la estrategia
   de b√∫squeda para reducir comandos de 5 a 2 sin perder informaci√≥n?"
   ```

3. **Mejora del retry logic**
   ```
   Ejercicio:
   1. Haz que un issue falle intencionalmente (tests fail)
   2. Analiza c√≥mo el agente maneja el retry
   3. Usa IA para mejorar el retry logic

   Prompt:
   "Este agente falla el mismo test 3 veces por el mismo error. ¬øC√≥mo
   dise√±ar√≠as un sistema de retry que aprenda del error anterior?"
   ```

---

## üîß Parte 4: Debugging de agentes con IA (80% IA)

### T√©cnicas de debugging asistidas por IA

#### 1. Log analysis con IA
```
Prompt a Claude Code:
"Analiza este log de ejecuci√≥n del agente. Identifica:
1. ¬øD√≥nde se qued√≥ atascado?
2. ¬øQu√© decisiones tom√≥ que no tienen sentido?
3. ¬øHay loops infinitos o comportamiento repetitivo?
4. Sugiere 3 mejoras espec√≠ficas al c√≥digo."
```

#### 2. Prompt engineering iterativo
```
Experimento con IA:
1. Ejecuta agente con prompt versi√≥n 1
2. Analiza comportamiento con Claude Code
3. Claude Code sugiere mejoras al prompt
4. Ejecuta con prompt versi√≥n 2
5. Compara resultados

Meta-an√°lisis: ¬øQu√© elementos del prompt m√°s influyen en el comportamiento?
```

#### 3. Tool selection debugging
```
Si Claude no usa tus tools correctamente:

Prompt a Claude Code:
"Claude ignora mi FileSearchTool y usa bash directamente. Aqu√≠ est√°
la descripci√≥n de la tool: [...]
¬øC√≥mo mejorar√≠as la descripci√≥n para que Claude la prefiera sobre bash?"
```

---

## üìä Parte 5: Evaluaci√≥n y m√©tricas (IA-assisted)

### M√©tricas para agentes

**Usa IA para analizar**:

1. **Success rate**
   ```
   Prompt:
   "Tengo estos resultados de 10 ejecuciones del agente: [...]
   Calcula: success rate, tiempo promedio, retry rate.
   ¬øQu√© patrones ves en los fallos?"
   ```

2. **Token efficiency**
   ```
   Prompt:
   "El agente usa 50K tokens promedio por tarea. Aqu√≠ est√° el breakdown:
   [context gathering: 20K, fix generation: 25K, synthesis: 5K]
   ¬øD√≥nde puedo optimizar? Sugiere estrategias concretas."
   ```

3. **Quality assessment**
   ```
   Usa LLM-as-judge para evaluar calidad del c√≥digo generado:

   Prompt al juez:
   "Eval√∫a este fix generado por agente en escala 1-10:
   - Correcci√≥n (¬øresuelve el issue?)
   - Calidad del c√≥digo (PEP 8, clean code)
   - Robustez (manejo de edge cases)
   Justifica cada puntuaci√≥n."
   ```

---

## üöÄ Parte 6: Extensiones avanzadas (100% IA)

### Proyecto extendido con IA

1. **Multi-modal agents**
   ```
   Extiende el agente para manejar issues de UI:
   - Genera fix de UI
   - Toma screenshot (visual feedback)
   - IA analiza screenshot vs dise√±o esperado
   - Itera hasta que UI sea correcta

   Prompt:
   "Dise√±a el workflow de un agente que arregla issues de UI usando
   screenshots como feedback. ¬øQu√© herramientas necesito? ¬øC√≥mo
   describo la diferencia entre esperado vs actual a Claude?"
   ```

2. **Agent orchestration**
   ```
   Crea meta-agente que decide qu√© agente especializado usar:

   Issues ‚Üí Meta-agent (classifier) ‚Üí [Agent A, Agent B, Agent C]

   Meta-agent usa Claude para:
   - Clasificar issue
   - Elegir agente apropiado
   - Validar resultado
   - Escalar a humano si es complejo
   ```

3. **Self-improving agents**
   ```
   Agente que aprende de errores:
   - Guarda casos de √©xito/fallo en vector DB
   - En nueva tarea, busca casos similares
   - Ajusta estrategia bas√°ndose en casos previos

   Usa IA para:
   - Generar embeddings de issues
   - Buscar casos similares (semantic search)
   - Sintetizar "lessons learned" de casos previos
   ```

---

## üéì R√∫brica de evaluaci√≥n (IA-assisted)

### Autoevaluaci√≥n con IA

Usa este prompt con Claude Code para evaluarte:

```
Eval√∫a mi implementaci√≥n del proyecto final en estas dimensiones:

1. **Arquitectura del agente** (0-10)
   - ¬øImplementa feedback loop correctamente?
   - ¬øManeja estados apropiadamente?
   - ¬øLas tools est√°n bien dise√±adas?

2. **Manejo de errores** (0-10)
   - ¬øRetry logic es robusto?
   - ¬øDetecta fallos irrecuperables?
   - ¬øLogs son √∫tiles para debugging?

3. **Calidad del c√≥digo generado** (0-10)
   - ¬øLos fixes resuelven el issue?
   - ¬øEl c√≥digo sigue PEP 8?
   - ¬øPasa tests y linting?

4. **Eficiencia** (0-10)
   - ¬øUso de tokens es razonable?
   - ¬øEvita comandos redundantes?
   - ¬øParaleliza donde es apropiado?

Aqu√≠ est√° mi c√≥digo: [...]

Para cada dimensi√≥n:
- Puntuaci√≥n (0-10)
- Justificaci√≥n
- 2 sugerencias de mejora espec√≠ficas
```

---

## üîó Integraci√≥n con otras clases

### Clase 6 (LangChain) ‚Üî Clase 6.5 (Claude Agent SDK)

**Ejercicio comparativo** (IA-assisted):

```
Prompt:
"Compara estas dos implementaciones del mismo agente:
1. Con LangChain (Clase 6)
2. Con Claude Agent SDK (Clase 6.5)

Analiza:
- L√≠neas de c√≥digo
- Control sobre el loop
- Facilidad de debugging
- Performance (tokens usados)
- Cu√°l elegir√≠as para producci√≥n y por qu√©?"
```

### Clase 6.6 (Context Engineering) - Preview

El agente aut√≥nomo usa context engineering:
- C√≥mo estructurar el system prompt de cada subagente
- C√≥mo comprimir contexto para evitar token limits
- Cu√°ndo usar compaction vs subagents

**Ejercicio de transici√≥n**:
```
Prompt a Claude Code:
"Mi agente aut√≥nomo alcanza token limit en proyectos grandes.
¬øQu√© estrategias de context engineering puedo aplicar?
Dame 3 t√©cnicas con ejemplos de c√≥digo."
```

---

## üìù Checklist de integraci√≥n IA

Verifica que tu aprendizaje incluya:

- [ ] ‚úÖ Usaste Anthropic API directamente (no abstracciones)
- [ ] ‚úÖ Implementaste feedback loop completo con IA
- [ ] ‚úÖ Dise√±aste tools y usaste Claude para invocarlas
- [ ] ‚úÖ Aplicaste LLM-as-judge para verificaci√≥n
- [ ] ‚úÖ Creaste subagentes especializados con system prompts
- [ ] ‚úÖ Usaste IA para debugging (an√°lisis de logs)
- [ ] ‚úÖ Experimentaste con prompt engineering
- [ ] ‚úÖ Mediste m√©tricas (tokens, success rate)
- [ ] ‚úÖ Proyecto final: agente aut√≥nomo funcional
- [ ] ‚úÖ Comparaste Claude Agent SDK vs LangChain

---

## üéØ Objetivo final

Al terminar esta clase, deber√≠as ser capaz de:

1. **Construir agentes aut√≥nomos profesionales** con Claude Agent SDK
2. **Dise√±ar architecturas de agentes** (single, multi-agent, hierarchical)
3. **Debuggear agentes** usando t√©cnicas de IA-assisted debugging
4. **Optimizar performance** de agentes (tokens, latencia, calidad)
5. **Decidir cu√°ndo usar** Claude SDK vs LangChain vs custom loop

Todo esto usando IA como herramienta central de aprendizaje, no solo de ejecuci√≥n.

---

**Meta-pregunta final**:

```
Prompt reflexivo a Claude Code:
"He completado la Clase 6.5. Reflexiona:
1. ¬øQu√© conceptos de agentes entiendo bien?
2. ¬øQu√© √°reas necesito profundizar?
3. ¬øC√≥mo aplicar√≠a estos conceptos en un proyecto real?
4. ¬øQu√© pregunta sobre agentes tengo que NO se cubri√≥ en la clase?"
```

Esta meta-pregunta cierra el loop de aprendizaje con IA üéìü§ñ
