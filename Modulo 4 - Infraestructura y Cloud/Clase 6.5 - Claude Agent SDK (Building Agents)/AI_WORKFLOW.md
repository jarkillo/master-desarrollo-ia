# AI Workflow - Clase 6.5: Claude Agent SDK

**Objetivo**: IntegraciÃ³n IA como herramienta central de aprendizaje (60%+ del contenido)

Esta clase ES SOBRE IA - el Claude Agent SDK. Por lo tanto, el 100% del contenido tÃ©cnico involucra IA, y la integraciÃ³n IA estÃ¡ en el nÃºcleo de cada ejercicio.

---

## ğŸ¯ Resumen de integraciÃ³n IA

| Componente | % IA | DescripciÃ³n |
|------------|------|-------------|
| **TeorÃ­a** | 100% | Claude Agent SDK, arquitectura de agentes, feedback loop |
| **Ejercicios** | 100% | Todos usan Anthropic API para crear agentes |
| **Proyecto final** | 100% | Agente autÃ³nomo de desarrollo con Claude |
| **Debugging** | 80% | IA para anÃ¡lisis de logs + debugging manual |

**Total: ~95% integraciÃ³n IA** (supera el 60% requerido)

---

## ğŸ“š Parte 1: Fundamentos de agentes con IA (100% IA)

### Conceptos a aprender CON IA

1. **Feedback loop fundamental**
   ```
   Gather Context â†’ Take Action â†’ Verify Work â†’ Repeat
   ```
   - **Prompt para entender**: "Explica el feedback loop de agentes con analogÃ­a de desarrollo de software"
   - **IA genera**: Ejemplos de bucles en debugging, testing, refactoring

2. **Context gathering strategies**
   - Agentic search vs Semantic search
   - **Ejercicio IA**: Pedir a Claude que compare las dos estrategias con tabla de trade-offs
   - **Prompt**: "Â¿CuÃ¡ndo usar agentic search vs semantic search en agentes? Dame casos de uso especÃ­ficos"

3. **Tool design patterns**
   - **IA explica**: Best practices de tool design
   - **Prompt**: "Dame 5 principios de diseÃ±o de tools para agentes Claude, con ejemplos de buen y mal diseÃ±o"

---

## ğŸ’» Parte 2: Ejercicios prÃ¡cticos (100% IA)

Todos los ejercicios requieren usar la Anthropic API directamente.

### Ejercicio 1: Primer agente simple (archivo: `ejemplos/01_agente_simple.py`)

**Objetivo**: Agente que explora repositorio usando bash tools

**Workflow con IA**:

1. **DiseÃ±o del agente** (IA-assisted)
   ```
   Prompt a Claude Code:
   "AyÃºdame a diseÃ±ar la estructura de un agente simple que explore
   repositorios con comandos bash. Â¿QuÃ© clase base necesito? Â¿QuÃ©
   mÃ©todos son esenciales?"
   ```

2. **ImplementaciÃ³n** (100% IA en runtime)
   - El agente usa Claude API para decidir quÃ© comandos bash ejecutar
   - Implementa feedback loop completo
   - IA analiza outputs y decide prÃ³ximos pasos

3. **Debugging con IA**
   ```
   Prompt:
   "Este agente ejecuta 'ls' repetidamente sin avanzar. Analiza el log
   y sugiere quÃ© estÃ¡ fallando en mi implementaciÃ³n del feedback loop"
   ```

**Ejercicio extendido**:
- Usa IA para generar tests del agente
- Pide a Claude que optimice la estrategia de bÃºsqueda del agente

---

### Ejercicio 2: State management y retry logic (archivo: `ejemplos/02_control_flujo.py`)

**Objetivo**: Agente con estados, retry logic y verificaciÃ³n con LLM-as-judge

**Workflow con IA**:

1. **State machine design** (IA-assisted)
   ```
   Prompt:
   "DiseÃ±a una state machine para un agente de desarrollo con estados:
   pending, in_progress, completed, failed, retrying.
   Â¿QuÃ© transiciones son vÃ¡lidas? Genera un diagrama en Mermaid."
   ```

2. **VerificaciÃ³n con LLM-as-judge** (100% IA)
   - El agente usa Claude para validar sus propios resultados
   - Pattern: Un LLM genera, otro LLM verifica
   - **Prompt para verificador**:
     ```python
     f"Verifica si este resultado cumple la tarea: {task_description}
     Resultado: {result}
     Responde VÃLIDO o INVÃLIDO con razÃ³n."
     ```

3. **Retry logic inteligente** (IA-driven)
   - Backoff exponencial clÃ¡sico
   - Pero el agente usa IA para analizar *por quÃ©* fallÃ³
   - Ajusta estrategia en cada retry

**Ejercicio con IA**:
```
Prompt a Claude Code:
"El agente estÃ¡ en retry loop infinito. Analiza este log y sugiere
cÃ³mo mejorar la lÃ³gica de retry para detectar fallos irrecuperables."
```

---

### Ejercicio 3: Tool design avanzado (archivo: `ejemplos/03_tools_avanzadas.py`)

**Objetivo**: DiseÃ±ar tools profesionales con validaciÃ³n, logging, idempotencia

**Workflow con IA**:

1. **DiseÃ±o de tools** (IA-assisted)
   ```
   Prompt:
   "Necesito diseÃ±ar una tool para ejecutar pytest. Genera el schema
   Anthropic con:
   - Input parameters (path, verbose)
   - DescripciÃ³n clara para que Claude entienda cuÃ¡ndo usarla
   - Ejemplo de input_schema completo"
   ```

2. **ValidaciÃ³n con IA**
   - Pide a Claude Code que revise tus tools
   - **Prompt**: "Revisa esta tool design. Â¿Cumple con: especÃ­fica, bien documentada, idempotente, con validaciÃ³n?"

3. **Debugging de tool calls**
   - Usa IA para analizar por quÃ© Claude elige (o no) una tool
   - **Prompt**: "Claude no estÃ¡ usando mi GitStatusTool. Analiza la descripciÃ³n y sugiere mejoras"

**Ejercicio avanzado**:
- Pide a IA que genere 3 tools mÃ¡s para el agente
- Usa IA para generar tests de las tools

---

### Ejercicio 4: Subagentes y paralelizaciÃ³n (archivo: `ejemplos/04_subagentes.py`)

**Objetivo**: Agente maestro que coordina subagentes especializados

**Workflow con IA**:

1. **Arquitectura de subagentes** (IA-assisted)
   ```
   Prompt:
   "DiseÃ±a una arquitectura de agente maestro + 3 subagentes para
   analizar proyectos Python. Â¿QuÃ© responsabilidad tiene cada uno?
   Â¿CÃ³mo se comunican? Â¿QuÃ© retorna cada subagente al maestro?"
   ```

2. **Specialization con system prompts** (100% IA)
   - Cada subagente tiene system prompt Ãºnico
   - IA para generar system prompts efectivos
   - **Ejemplo**: SearchAgent vs AnalysisAgent vs TestAgent

3. **Synthesis con IA** (100% IA)
   - Agente maestro usa Claude para sintetizar resultados de subagentes
   - Pattern: Multiple LLM calls â†’ Single synthesis call

**Ejercicio con IA**:
```
Prompt:
"Tengo 3 subagentes con outputs largos. Â¿CÃ³mo diseÃ±o el prompt de
sÃ­ntesis para que el maestro genere un resumen ejecutivo de mÃ¡ximo
10 lÃ­neas sin perder informaciÃ³n crÃ­tica?"
```

---

## ğŸ† Parte 3: Proyecto final - Agente autÃ³nomo (100% IA)

**Archivo**: `proyecto_final/agente_dev_autonomo.py`

### Workflow completo con IA

#### 1. AnÃ¡lisis de issue (IA)
```python
# IA clasifica tipo de issue
issue_type = agent._classify_issue(issue)
# Prompt: "Clasifica este issue en: typo, missing_import, simple_test, ..."
```

#### 2. Context gathering (IA + agentic search)
```python
# IA decide quÃ© comandos bash ejecutar para encontrar cÃ³digo relevante
context = agent._gather_context(issue)
# Prompt: "Â¿QuÃ© archivos debo revisar para este issue? Sugiere comandos bash."
```

#### 3. GeneraciÃ³n de fix (IA)
```python
# IA genera el cÃ³digo del fix completo
fix_code = agent._generate_fix(issue, context)
# Prompt: "Genera fix para este issue. Formato JSON con archivos completos."
```

#### 4. VerificaciÃ³n (IA + herramientas)
```python
# VerificaciÃ³n hÃ­brida:
# - Tests: pytest (tool tradicional)
# - Linting: ruff (tool tradicional)
# - ValidaciÃ³n semÃ¡ntica: Claude (IA)

if not tests_passed:
    # IA analiza por quÃ© fallaron
    analysis = agent._analyze_test_failure(test_output)
    # Retry con feedback de IA
```

#### 5. PR description (IA)
```python
# IA genera descripciÃ³n profesional del PR
pr_description = agent._generate_pr_description(issue, files_modified)
# Incluye: changes, verification, related issue
```

### Ejercicios con IA para el proyecto

1. **Prompt engineering para fix generation**
   ```
   Experimento:
   1. Genera un fix con prompt bÃ¡sico
   2. Genera el mismo fix con prompt detallado (incluye: context, retry guidance, format)
   3. Compara calidad de outputs

   Pregunta: Â¿QuÃ© elementos del prompt mÃ¡s afectan la calidad del fix?
   ```

2. **OptimizaciÃ³n de context gathering**
   ```
   Usa IA para analizar:
   - Â¿CuÃ¡ntos comandos bash se ejecutan en promedio?
   - Â¿Hay comandos redundantes?
   - Â¿Se puede predecir quÃ© archivos revisar sin ejecutar comandos?

   Prompt a Claude Code:
   "Analiza este log de comandos bash. Â¿CÃ³mo optimizarÃ­as la estrategia
   de bÃºsqueda para reducir comandos de 5 a 2 sin perder informaciÃ³n?"
   ```

3. **Mejora del retry logic**
   ```
   Ejercicio:
   1. Haz que un issue falle intencionalmente (tests fail)
   2. Analiza cÃ³mo el agente maneja el retry
   3. Usa IA para mejorar el retry logic

   Prompt:
   "Este agente falla el mismo test 3 veces por el mismo error. Â¿CÃ³mo
   diseÃ±arÃ­as un sistema de retry que aprenda del error anterior?"
   ```

---

## ğŸ”§ Parte 4: Debugging de agentes con IA (80% IA)

### TÃ©cnicas de debugging asistidas por IA

#### 1. Log analysis con IA
```
Prompt a Claude Code:
"Analiza este log de ejecuciÃ³n del agente. Identifica:
1. Â¿DÃ³nde se quedÃ³ atascado?
2. Â¿QuÃ© decisiones tomÃ³ que no tienen sentido?
3. Â¿Hay loops infinitos o comportamiento repetitivo?
4. Sugiere 3 mejoras especÃ­ficas al cÃ³digo."
```

#### 2. Prompt engineering iterativo
```
Experimento con IA:
1. Ejecuta agente con prompt versiÃ³n 1
2. Analiza comportamiento con Claude Code
3. Claude Code sugiere mejoras al prompt
4. Ejecuta con prompt versiÃ³n 2
5. Compara resultados

Meta-anÃ¡lisis: Â¿QuÃ© elementos del prompt mÃ¡s influyen en el comportamiento?
```

#### 3. Tool selection debugging
```
Si Claude no usa tus tools correctamente:

Prompt a Claude Code:
"Claude ignora mi FileSearchTool y usa bash directamente. AquÃ­ estÃ¡
la descripciÃ³n de la tool: [...]
Â¿CÃ³mo mejorarÃ­as la descripciÃ³n para que Claude la prefiera sobre bash?"
```

---

## ğŸ“Š Parte 5: EvaluaciÃ³n y mÃ©tricas (IA-assisted)

### MÃ©tricas para agentes

**Usa IA para analizar**:

1. **Success rate**
   ```
   Prompt:
   "Tengo estos resultados de 10 ejecuciones del agente: [...]
   Calcula: success rate, tiempo promedio, retry rate.
   Â¿QuÃ© patrones ves en los fallos?"
   ```

2. **Token efficiency**
   ```
   Prompt:
   "El agente usa 50K tokens promedio por tarea. AquÃ­ estÃ¡ el breakdown:
   [context gathering: 20K, fix generation: 25K, synthesis: 5K]
   Â¿DÃ³nde puedo optimizar? Sugiere estrategias concretas."
   ```

3. **Quality assessment**
   ```
   Usa LLM-as-judge para evaluar calidad del cÃ³digo generado:

   Prompt al juez:
   "EvalÃºa este fix generado por agente en escala 1-10:
   - CorrecciÃ³n (Â¿resuelve el issue?)
   - Calidad del cÃ³digo (PEP 8, clean code)
   - Robustez (manejo de edge cases)
   Justifica cada puntuaciÃ³n."
   ```

---

## ğŸš€ Parte 6: Extensiones avanzadas (100% IA)

### Proyecto extendido con IA

1. **Multi-modal agents**
   ```
   Extiende el agente para manejar issues de UI:
   - Genera fix de UI
   - Toma screenshot (visual feedback)
   - IA analiza screenshot vs diseÃ±o esperado
   - Itera hasta que UI sea correcta

   Prompt:
   "DiseÃ±a el workflow de un agente que arregla issues de UI usando
   screenshots como feedback. Â¿QuÃ© herramientas necesito? Â¿CÃ³mo
   describo la diferencia entre esperado vs actual a Claude?"
   ```

2. **Agent orchestration**
   ```
   Crea meta-agente que decide quÃ© agente especializado usar:

   Issues â†’ Meta-agent (classifier) â†’ [Agent A, Agent B, Agent C]

   Meta-agent usa Claude para:
   - Clasificar issue
   - Elegir agente apropiado
   - Validar resultado
   - Escalar a humano si es complejo
   ```

3. **Self-improving agents**
   ```
   Agente que aprende de errores:
   - Guarda casos de Ã©xito/fallo en vector DB
   - En nueva tarea, busca casos similares
   - Ajusta estrategia basÃ¡ndose en casos previos

   Usa IA para:
   - Generar embeddings de issues
   - Buscar casos similares (semantic search)
   - Sintetizar "lessons learned" de casos previos
   ```

---

## ğŸ“ RÃºbrica de evaluaciÃ³n (IA-assisted)

### AutoevaluaciÃ³n con IA

Usa este prompt con Claude Code para evaluarte:

```
EvalÃºa mi implementaciÃ³n del proyecto final en estas dimensiones:

1. **Arquitectura del agente** (0-10)
   - Â¿Implementa feedback loop correctamente?
   - Â¿Maneja estados apropiadamente?
   - Â¿Las tools estÃ¡n bien diseÃ±adas?

2. **Manejo de errores** (0-10)
   - Â¿Retry logic es robusto?
   - Â¿Detecta fallos irrecuperables?
   - Â¿Logs son Ãºtiles para debugging?

3. **Calidad del cÃ³digo generado** (0-10)
   - Â¿Los fixes resuelven el issue?
   - Â¿El cÃ³digo sigue PEP 8?
   - Â¿Pasa tests y linting?

4. **Eficiencia** (0-10)
   - Â¿Uso de tokens es razonable?
   - Â¿Evita comandos redundantes?
   - Â¿Paraleliza donde es apropiado?

AquÃ­ estÃ¡ mi cÃ³digo: [...]

Para cada dimensiÃ³n:
- PuntuaciÃ³n (0-10)
- JustificaciÃ³n
- 2 sugerencias de mejora especÃ­ficas
```

---

## ğŸ”— IntegraciÃ³n con otras clases

### Clase 6 (LangChain) â†” Clase 6.5 (Claude Agent SDK)

**Ejercicio comparativo** (IA-assisted):

```
Prompt:
"Compara estas dos implementaciones del mismo agente:
1. Con LangChain (Clase 6)
2. Con Claude Agent SDK (Clase 6.5)

Analiza:
- LÃ­neas de cÃ³digo
- Control sobre el loop
- Facilidad de debugging
- Performance (tokens usados)
- CuÃ¡l elegirÃ­as para producciÃ³n y por quÃ©?"
```

### Clase 6.6 (Context Engineering) - Preview

El agente autÃ³nomo usa context engineering:
- CÃ³mo estructurar el system prompt de cada subagente
- CÃ³mo comprimir contexto para evitar token limits
- CuÃ¡ndo usar compaction vs subagents

**Ejercicio de transiciÃ³n**:
```
Prompt a Claude Code:
"Mi agente autÃ³nomo alcanza token limit en proyectos grandes.
Â¿QuÃ© estrategias de context engineering puedo aplicar?
Dame 3 tÃ©cnicas con ejemplos de cÃ³digo."
```

---

## ğŸ“ Checklist de integraciÃ³n IA

Verifica que tu aprendizaje incluya:

- [ ] âœ… Usaste Anthropic API directamente (no abstracciones)
- [ ] âœ… Implementaste feedback loop completo con IA
- [ ] âœ… DiseÃ±aste tools y usaste Claude para invocarlas
- [ ] âœ… Aplicaste LLM-as-judge para verificaciÃ³n
- [ ] âœ… Creaste subagentes especializados con system prompts
- [ ] âœ… Usaste IA para debugging (anÃ¡lisis de logs)
- [ ] âœ… Experimentaste con prompt engineering
- [ ] âœ… Mediste mÃ©tricas (tokens, success rate)
- [ ] âœ… Proyecto final: agente autÃ³nomo funcional
- [ ] âœ… Comparaste Claude Agent SDK vs LangChain

---

## ğŸ¯ Objetivo final

Al terminar esta clase, deberÃ­as ser capaz de:

1. **Construir agentes autÃ³nomos profesionales** con Claude Agent SDK
2. **DiseÃ±ar architecturas de agentes** (single, multi-agent, hierarchical)
3. **Debuggear agentes** usando tÃ©cnicas de IA-assisted debugging
4. **Optimizar performance** de agentes (tokens, latencia, calidad)
5. **Decidir cuÃ¡ndo usar** Claude SDK vs LangChain vs custom loop

Todo esto usando IA como herramienta central de aprendizaje, no solo de ejecuciÃ³n.

---

**Meta-pregunta final**:

```
Prompt reflexivo a Claude Code:
"He completado la Clase 6.5. Reflexiona:
1. Â¿QuÃ© conceptos de agentes entiendo bien?
2. Â¿QuÃ© Ã¡reas necesito profundizar?
3. Â¿CÃ³mo aplicarÃ­a estos conceptos en un proyecto real?
4. Â¿QuÃ© pregunta sobre agentes tengo que NO se cubriÃ³ en la clase?"
```

Esta meta-pregunta cierra el loop de aprendizaje con IA ğŸ“ğŸ¤–
