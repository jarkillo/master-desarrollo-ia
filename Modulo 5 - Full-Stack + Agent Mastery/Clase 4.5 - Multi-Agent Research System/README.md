# M√≥dulo 5 - Clase 4.5: Multi-Agent Research System

**Construye tu primer sistema de investigaci√≥n multi-agente** - Aprende c√≥mo m√∫ltiples agentes especializados colaboran para resolver tareas complejas que un solo agente no podr√≠a manejar eficientemente.

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [¬øQu√© es un Sistema Multi-Agente?](#qu√©-es-un-sistema-multi-agente)
3. [Arquitectura de Agentes Especializados](#arquitectura-de-agentes-especializados)
4. [Patrones de Comunicaci√≥n entre Agentes](#patrones-de-comunicaci√≥n-entre-agentes)
5. [Implementaci√≥n Pr√°ctica](#implementaci√≥n-pr√°ctica)
6. [Gesti√≥n de Memoria y Estado](#gesti√≥n-de-memoria-y-estado)
7. [Debugging y Observabilidad](#debugging-y-observabilidad)
8. [Proyecto: Sistema de Research para Documentaci√≥n](#proyecto-sistema-de-research-para-documentaci√≥n)
9. [Ejercicios Pr√°cticos](#ejercicios-pr√°cticos)
10. [Recursos Adicionales](#recursos-adicionales)

---

## Introducci√≥n

### El Problema que Resuelven los Sistemas Multi-Agente

Imagina que necesitas investigar **"El impacto de la IA en la industria automotriz"**.

**Enfoque tradicional (un solo agente)**:
```
Usuario ‚Üí Claude ‚Üí Busca todo ‚Üí Procesa todo ‚Üí Respuesta
```
**Problemas**:
- ‚ùå El agente se abruma con demasiados aspectos (manufactura, dise√±o, seguridad, regulaciones)
- ‚ùå Informaci√≥n superficial (toca muchos temas pero ninguno en profundidad)
- ‚ùå Trabajo duplicado (busca lo mismo varias veces desde diferentes √°ngulos)
- ‚ùå Resultados inconsistentes (pierde el hilo entre subtemas)

**Enfoque multi-agente**:
```
Usuario ‚Üí Lead Agent (Orquestador)
              ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì         ‚Üì         ‚Üì         ‚Üì
Researcher  Researcher Researcher Researcher
(Manufactura) (Dise√±o) (Seguridad) (Regulaciones)
    ‚Üì         ‚Üì         ‚Üì         ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
     CitationAgent (verifica fuentes)
              ‚Üì
          S√≠ntesis final
```

**Ventajas**:
- ‚úÖ **Especializaci√≥n**: Cada agente se enfoca en un subtema espec√≠fico
- ‚úÖ **Profundidad**: Investigaci√≥n exhaustiva por √°rea
- ‚úÖ **Paralelizaci√≥n**: Agentes trabajan simult√°neamente (90% m√°s r√°pido)
- ‚úÖ **Divisi√≥n del trabajo**: Sin duplicaci√≥n, sin overlap
- ‚úÖ **Escalabilidad**: Agrega m√°s agentes para tareas m√°s complejas

**Datos reales del art√≠culo de Anthropic**:
- üöÄ **90.2% mejor performance** en queries de breadth-first
- ‚ö° **90% reducci√≥n en tiempo** gracias a paralelizaci√≥n
- üí∞ **15x m√°s tokens** pero con resultados cualitativamente superiores

---

## ¬øQu√© es un Sistema Multi-Agente?

### Definici√≥n

Un **sistema multi-agente** es una arquitectura donde m√∫ltiples agentes de IA especializados colaboran para resolver una tarea compleja que requiere:

1. **Divisi√≥n de trabajo** en subtareas especializadas
2. **Comunicaci√≥n** entre agentes para compartir resultados
3. **Coordinaci√≥n** para evitar duplicaci√≥n y conflictos
4. **Agregaci√≥n** de resultados en una respuesta coherente

### Analog√≠a: Equipo de Investigadores Acad√©micos

| Elemento | En Academia | En Sistema Multi-Agente |
|----------|-------------|-------------------------|
| **L√≠der del proyecto** | Profesor principal | Lead Agent (Orchestrator) |
| **Investigadores** | Doctorandos especializados | Subagents (Workers) |
| **√Årea de expertise** | Cada uno investiga un subtema | Cada agente tiene un objetivo espec√≠fico |
| **Comunicaci√≥n** | Reuniones semanales | Message passing entre agentes |
| **Paper final** | Coautor√≠a, todos contribuyen | S√≠ntesis de resultados |
| **Revisi√≥n de fuentes** | Peer review | CitationAgent verifica credibilidad |

**Clave**: El profesor (Lead Agent) no investiga todo. Divide el problema, asigna subtemas, y coordina las contribuciones.

### Componentes Principales

```python
# Estructura conceptual de un sistema multi-agente

class MultiAgentSystem:
    """
    Sistema de investigaci√≥n multi-agente.

    Componentes:
    - Lead Agent: Planifica y coordina
    - Subagents: Ejecutan investigaci√≥n especializada
    - Message Bus: Comunicaci√≥n entre agentes
    - Shared Memory: Estado compartido
    - Citation Verifier: Valida fuentes
    """

    def __init__(self):
        self.lead_agent = LeadAgent()
        self.subagents = []
        self.message_bus = MessageBus()
        self.shared_memory = SharedMemory()
        self.citation_verifier = CitationAgent()

    async def research(self, query: str) -> str:
        """
        Proceso de investigaci√≥n multi-agente.

        1. Lead agent analiza query y planifica estrategia
        2. Lead agent crea subagents especializados
        3. Subagents investigan en paralelo
        4. Lead agent agrega resultados
        5. Citation verifier valida fuentes
        6. Retorna s√≠ntesis final
        """
        # Paso 1: Planificaci√≥n
        plan = await self.lead_agent.create_research_plan(query)

        # Paso 2: Crear subagents especializados
        self.subagents = [
            SubAgent(task) for task in plan.tasks
        ]

        # Paso 3: Investigaci√≥n paralela
        results = await asyncio.gather(*[
            agent.research() for agent in self.subagents
        ])

        # Paso 4: Agregar resultados
        synthesis = await self.lead_agent.synthesize(results)

        # Paso 5: Verificar citaciones
        verified = await self.citation_verifier.verify(synthesis)

        return verified
```

---

## Arquitectura de Agentes Especializados

### 1. Lead Agent (Orquestador)

**Responsabilidades**:
- üìã Analizar la query del usuario
- üéØ Desarrollar estrategia de investigaci√≥n
- ü§ù Crear y asignar tareas a subagents
- üîÑ Esperar resultados (ejecuci√≥n s√≠ncrona)
- üìä Sintetizar resultados finales
- ‚ö†Ô∏è Detectar gaps y lanzar investigaci√≥n adicional

**Caracter√≠sticas t√©cnicas** (seg√∫n Anthropic):
- Usa **extended thinking** para planificar
- Opera **s√≠ncronamente** (espera a que subagents terminen)
- Determina **resource allocation** (cu√°ntos agentes, cu√°ntas b√∫squedas)
- Maneja **context limits** guardando en memoria externa

**Ejemplo de prompt para Lead Agent**:
```
Eres el Lead Agent de un sistema de investigaci√≥n.

Tu tarea: Analizar la siguiente query y crear un plan de investigaci√≥n:
"{user_query}"

Genera un plan con:
1. Subtareas espec√≠ficas (cada una asignable a un subagent)
2. Objetivos claros para cada subtarea
3. Formato de output esperado
4. Fuentes/herramientas a usar
5. Criterios de √©xito

Reglas de scaling (seg√∫n complejidad):
- Fact-finding simple: 1 agente, 3-10 tool calls
- Comparaciones: 2-4 subagents, 10-15 calls cada uno
- Research complejo: 10+ subagents con responsabilidades divididas

Output en formato JSON:
{
  "tasks": [
    {
      "id": 1,
      "description": "Investigar impacto de IA en manufactura automotriz",
      "agent_role": "Manufacturing Researcher",
      "tools": ["web_search", "academic_search"],
      "max_searches": 15,
      "success_criteria": "Identificar 5+ casos de uso con datos cuantitativos"
    },
    ...
  ],
  "estimated_complexity": "high",
  "estimated_agents": 4
}
```

### 2. Subagents (Workers)

**Responsabilidades**:
- üîç Ejecutar investigaci√≥n especializada en un subtema
- üìö Realizar b√∫squedas iterativas (web, academic papers, docs)
- üß† Usar **interleaved thinking** para evaluar resultados
- üîÑ Identificar gaps y ajustar b√∫squedas
- üìù Retornar findings al Lead Agent

**Caracter√≠sticas t√©cnicas**:
- Reciben **objetivos claros** del Lead Agent
- **Autonom√≠a** para decidir estrategia de b√∫squeda
- **Iteran** hasta completar la tarea
- **Paralelizaci√≥n**: Pueden ejecutarse simult√°neamente

**Ejemplo de instrucciones para Subagent**:
```
Eres un Subagent especializado en: {specialty}

Objetivo: {task_description}

Output esperado:
- Formato: {expected_format}
- Longitud: {expected_length}
- Fuentes: M√≠nimo {min_sources} fuentes cre√≠bles

Herramientas disponibles:
{tools_list}

Guidance:
- Usa m√°ximo {max_searches} b√∫squedas
- Prioriza fuentes acad√©micas y oficiales sobre blogs
- Si encuentras informaci√≥n contradictoria, reporta ambas versiones
- Si no encuentras informaci√≥n suficiente, reporta el gap expl√≠citamente

Criterios de √©xito:
{success_criteria}

Itera hasta cumplir los criterios. Usa thinking para evaluar si necesitas m√°s b√∫squedas.
```

**Anti-patr√≥n (del art√≠culo de Anthropic)**:
```
‚ùå MALO - Instrucci√≥n vaga:
"Research the semiconductor shortage"

Problema: M√∫ltiples subagents investigaron el mismo tema
(shortage de 2021 en automotive + shortage de 2025 en chips)
sin divisi√≥n de trabajo clara.
```

```
‚úÖ BUENO - Instrucci√≥n espec√≠fica:
"Research the 2021 semiconductor shortage impact on automotive
manufacturing in North America. Focus on: production delays
(quantify in units), financial impact (revenue loss), and
recovery timeline. Time period: Jan 2021 - Dec 2022."

Resultado: Subagent sabe exactamente qu√© buscar, evita overlap.
```

### 3. Citation Agent (Verificador de Fuentes)

**Responsabilidades**:
- ‚úÖ Verificar que todas las afirmaciones tengan fuentes
- üîó Validar que los URLs sean accesibles
- üìä Evaluar credibilidad de fuentes (acad√©micas > blogs)
- üö´ Detectar claims sin evidencia
- üìù Formatear citaciones correctamente

**Por qu√© es necesario**:
- Los subagents pueden "alucinar" fuentes
- Asegurar trazabilidad de informaci√≥n
- Cumplir est√°ndares acad√©micos/profesionales

**Ejemplo**:
```
Eres el Citation Agent. Valida las fuentes del siguiente texto:

"{synthesis_text}"

Por cada claim:
1. Verificar que tenga citaci√≥n
2. Verificar que la fuente exista (URL accesible)
3. Evaluar credibilidad (academic > official > news > blog)
4. Si falta citaci√≥n, marcar como [NEEDS CITATION]

Output:
- Texto corregido con citaciones verificadas
- Lista de fuentes no verificables
- Score de credibilidad (0.0-1.0)
```

---

## Patrones de Comunicaci√≥n entre Agentes

### 1. Query Decomposition (Descomposici√≥n de Queries)

El Lead Agent divide queries complejas en subtareas discretas con instrucciones detalladas.

**Ejemplo real - Query compleja**:
```
"¬øC√≥mo est√°n las empresas automotrices adapt√°ndose a la era de los veh√≠culos el√©ctricos?"
```

**Descomposici√≥n por Lead Agent**:
```json
{
  "tasks": [
    {
      "id": 1,
      "subtask": "Inversi√≥n en infraestructura de carga",
      "agent_focus": "Investiga cu√°nto est√°n invirtiendo las top 5 automotrices (Tesla, VW, GM, Ford, Toyota) en estaciones de carga. Datos: inversi√≥n USD, n√∫mero de estaciones, timeline.",
      "output_format": "Tabla comparativa con datos cuantitativos"
    },
    {
      "id": 2,
      "subtask": "Desarrollo de bater√≠as",
      "agent_focus": "Investiga innovaciones en tecnolog√≠a de bater√≠as: densidad energ√©tica (Wh/kg), tiempo de carga, vida √∫til (ciclos), costos (USD/kWh). Compara LFP vs NMC vs solid-state.",
      "output_format": "An√°lisis t√©cnico con especificaciones"
    },
    {
      "id": 3,
      "subtask": "Adaptaci√≥n de l√≠neas de producci√≥n",
      "agent_focus": "Investiga c√≥mo las plantas tradicionales est√°n siendo retooled para EVs. Casos de estudio: tiempos de conversi√≥n, costos, desaf√≠os laborales.",
      "output_format": "Narrativa con 3+ casos espec√≠ficos"
    },
    {
      "id": 4,
      "subtask": "Regulaciones y subsidios",
      "agent_focus": "Mapea pol√≠ticas gubernamentales que incentivan EVs por regi√≥n (US, EU, China): subsidios, mandatos de ventas, prohibiciones de ICE.",
      "output_format": "Timeline de regulaciones 2020-2030"
    }
  ]
}
```

**Principio clave**: Instrucciones vagas ‚Üí trabajo duplicado. Instrucciones espec√≠ficas ‚Üí eficiencia.

### 2. Result Synthesis (S√≠ntesis de Resultados)

El Lead Agent agrega los findings de todos los subagents en una respuesta coherente.

**Pattern**:
```python
async def synthesize_results(self, subagent_results: List[AgentResult]) -> str:
    """
    Sintetiza resultados de m√∫ltiples subagents.

    Estrategia:
    1. Identificar temas comunes entre resultados
    2. Resolver contradicciones (si las hay)
    3. Llenar gaps (lanzar investigaci√≥n adicional si es necesario)
    4. Estructurar narrativa coherente
    5. Agregar executive summary
    """
    synthesis_prompt = f"""
    Eres el Lead Agent. Sintetiza los siguientes resultados de investigaci√≥n:

    {format_results(subagent_results)}

    Genera:
    1. Executive Summary (3-5 bullets)
    2. Findings detallados por √°rea
    3. Conclusiones integradas
    4. Gaps identificados (si los hay)

    Si encuentras contradicciones entre fuentes, rep√≥rtalas expl√≠citamente.
    """

    return await self.llm.complete(synthesis_prompt)
```

**Ciclo iterativo** (del art√≠culo de Anthropic):
```
Lead Agent ‚Üí Crea subagents ‚Üí Subagents investigan ‚Üí Lead sintetiza
     ‚Üë                                                       ‚Üì
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ¬øGaps detectados? ‚Üí Lanza nueva ronda ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3. Parallel Execution (Ejecuci√≥n Paralela)

**Dos tipos de paralelizaci√≥n** (seg√∫n Anthropic):

**Tipo 1: Lead agent spawns m√∫ltiples subagents**
```python
# Lead Agent lanza 3-5 subagents simult√°neamente
subagents = [
    SubAgent("Manufacturing Research"),
    SubAgent("Battery Technology"),
    SubAgent("Regulatory Landscape"),
]

# Ejecuci√≥n paralela (asyncio.gather)
results = await asyncio.gather(*[
    agent.research() for agent in subagents
])

# Reducci√≥n de tiempo: ~90% (seg√∫n Anthropic)
# Sequential: 15 min ‚Üí Parallel: 1.5 min
```

**Tipo 2: Subagents usan m√∫ltiples tools en paralelo**
```python
# Cada subagent ejecuta 3+ tool calls simult√°neamente
async def research(self):
    results = await asyncio.gather(
        self.web_search("EV battery technology 2024"),
        self.academic_search("lithium-ion energy density"),
        self.news_search("solid-state battery breakthroughs"),
    )
    return self.analyze(results)
```

**Impacto combinado**: Reducci√≥n dram√°tica en tiempo total.

---

## Implementaci√≥n Pr√°ctica

### Sistema B√°sico Multi-Agente (3 Agentes)

Vamos a implementar un sistema real de investigaci√≥n con:
- 1 Lead Agent (orquestador)
- 2 Subagents (workers especializados)
- 1 Message Bus (comunicaci√≥n)

**Archivo**: `multi_agent_system/core.py`

```python
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum
import asyncio

class AgentRole(str, Enum):
    """Roles de agentes en el sistema."""
    LEAD = "lead"
    RESEARCHER = "researcher"
    ANALYZER = "analyzer"
    WRITER = "writer"
    CITATION_VERIFIER = "citation_verifier"

@dataclass
class Task:
    """Tarea asignada a un subagent."""
    id: int
    description: str
    agent_role: AgentRole
    tools: List[str]
    max_searches: int
    success_criteria: str
    output_format: str

@dataclass
class AgentResult:
    """Resultado de investigaci√≥n de un agente."""
    task_id: int
    agent_role: AgentRole
    findings: str
    sources: List[str]
    confidence: float  # 0.0-1.0
    gaps_identified: List[str]

class MessageBus:
    """Bus de comunicaci√≥n entre agentes."""

    def __init__(self):
        self._messages: List[Dict[str, Any]] = []

    def publish(self, sender: str, receiver: str, message: Any):
        """Env√≠a mensaje de un agente a otro."""
        self._messages.append({
            "sender": sender,
            "receiver": receiver,
            "message": message,
            "timestamp": asyncio.get_event_loop().time()
        })

    def get_messages(self, receiver: str) -> List[Dict[str, Any]]:
        """Obtiene mensajes para un agente espec√≠fico."""
        return [m for m in self._messages if m["receiver"] == receiver]

class SharedMemory:
    """Memoria compartida entre agentes."""

    def __init__(self):
        self._data: Dict[str, Any] = {}

    def store(self, key: str, value: Any):
        """Almacena dato en memoria compartida."""
        self._data[key] = value

    def retrieve(self, key: str) -> Any:
        """Recupera dato de memoria compartida."""
        return self._data.get(key)

    def clear(self):
        """Limpia toda la memoria."""
        self._data.clear()

class LeadAgent:
    """
    Lead Agent (Orquestador).

    Responsabilidades:
    - Analizar query del usuario
    - Crear plan de investigaci√≥n
    - Asignar tareas a subagents
    - Sintetizar resultados
    """

    def __init__(self, llm_client, message_bus: MessageBus, memory: SharedMemory):
        self.llm = llm_client
        self.bus = message_bus
        self.memory = memory

    async def create_research_plan(self, query: str) -> List[Task]:
        """
        Crea plan de investigaci√≥n dividiendo la query en subtareas.

        Args:
            query: Query del usuario

        Returns:
            Lista de tareas para subagents
        """
        prompt = f"""
        Eres el Lead Agent de un sistema de investigaci√≥n multi-agente.

        Query del usuario: "{query}"

        Analiza la query y crea un plan de investigaci√≥n. Divide el problema
        en 2-4 subtareas espec√≠ficas que puedan ser investigadas en paralelo.

        Para cada subtarea, define:
        1. Descripci√≥n espec√≠fica (qu√© investigar exactamente)
        2. Rol del agente (researcher, analyzer)
        3. Herramientas a usar (web_search, academic_search)
        4. N√∫mero m√°ximo de b√∫squedas (3-15)
        5. Criterios de √©xito
        6. Formato de output esperado

        Reglas de scaling:
        - Simple (fact-finding): 1 agente, 3-10 b√∫squedas
        - Moderado (comparaci√≥n): 2-3 agentes, 10-15 b√∫squedas c/u
        - Complejo (an√°lisis profundo): 4+ agentes, 15+ b√∫squedas c/u

        Output en formato JSON.
        """

        # Aqu√≠ ir√≠a la llamada al LLM
        # response = await self.llm.complete(prompt)
        # tasks = parse_tasks_from_json(response)

        # Por ahora, ejemplo hardcodeado
        tasks = [
            Task(
                id=1,
                description="Investiga el impacto de IA en manufactura automotriz",
                agent_role=AgentRole.RESEARCHER,
                tools=["web_search", "academic_search"],
                max_searches=12,
                success_criteria="Identificar 5+ casos de uso con datos cuantitativos",
                output_format="Lista estructurada con ejemplos espec√≠ficos"
            ),
            Task(
                id=2,
                description="Analiza tendencias en veh√≠culos el√©ctricos 2020-2024",
                agent_role=AgentRole.ANALYZER,
                tools=["web_search", "data_analysis"],
                max_searches=10,
                success_criteria="Gr√°ficos de adopci√≥n por regi√≥n con datos",
                output_format="An√°lisis cuantitativo con visualizaciones"
            )
        ]

        # Guardar plan en memoria compartida
        self.memory.store("research_plan", tasks)

        return tasks

    async def synthesize_results(self, results: List[AgentResult]) -> str:
        """
        Sintetiza resultados de m√∫ltiples subagents.

        Args:
            results: Resultados de investigaci√≥n de cada subagent

        Returns:
            S√≠ntesis final
        """
        # Combinar findings
        all_findings = "\n\n".join([
            f"## {r.agent_role.value.title()} - Task {r.task_id}\n{r.findings}"
            for r in results
        ])

        # Combinar fuentes
        all_sources = []
        for r in results:
            all_sources.extend(r.sources)
        unique_sources = list(set(all_sources))

        prompt = f"""
        Eres el Lead Agent. Sintetiza los siguientes resultados de investigaci√≥n
        en una respuesta coherente y completa.

        RESULTADOS DE SUBAGENTS:
        {all_findings}

        FUENTES:
        {chr(10).join(f"- {s}" for s in unique_sources)}

        Genera:
        1. Executive Summary (3-5 puntos clave)
        2. Findings detallados por √°rea
        3. Conclusiones integradas
        4. Limitaciones y gaps (si los hay)

        Formato: Markdown profesional con secciones claras.
        """

        # Aqu√≠ ir√≠a la llamada al LLM
        # synthesis = await self.llm.complete(prompt)

        synthesis = f"""
        # S√≠ntesis de Investigaci√≥n

        ## Executive Summary
        - Hallazgo 1
        - Hallazgo 2
        - Hallazgo 3

        ## Findings Detallados
        {all_findings}

        ## Fuentes
        {chr(10).join(f"- {s}" for s in unique_sources)}
        """

        return synthesis

class SubAgent:
    """
    SubAgent (Worker).

    Responsabilidades:
    - Ejecutar investigaci√≥n especializada
    - Reportar resultados al Lead Agent
    """

    def __init__(
        self,
        task: Task,
        llm_client,
        message_bus: MessageBus,
        memory: SharedMemory
    ):
        self.task = task
        self.llm = llm_client
        self.bus = message_bus
        self.memory = memory

    async def research(self) -> AgentResult:
        """
        Ejecuta investigaci√≥n seg√∫n la tarea asignada.

        Returns:
            Resultados de investigaci√≥n
        """
        prompt = f"""
        Eres un {self.task.agent_role.value} especializado.

        TAREA: {self.task.description}

        HERRAMIENTAS DISPONIBLES: {", ".join(self.task.tools)}
        MAX B√öSQUEDAS: {self.task.max_searches}

        CRITERIOS DE √âXITO: {self.task.success_criteria}
        FORMATO ESPERADO: {self.task.output_format}

        Investiga exhaustivamente usando las herramientas disponibles.
        Usa thinking interleaved para evaluar si necesitas m√°s b√∫squedas.

        Si encuentras gaps en la informaci√≥n, rep√≥rtalos expl√≠citamente.
        """

        # Aqu√≠ ir√≠a:
        # 1. Llamadas iterativas al LLM con tool use
        # 2. Web searches
        # 3. Evaluaci√≥n de resultados

        # Por ahora, resultado de ejemplo
        result = AgentResult(
            task_id=self.task.id,
            agent_role=self.task.agent_role,
            findings=f"Findings para tarea {self.task.id}...",
            sources=[
                "https://example.com/source1",
                "https://example.com/source2"
            ],
            confidence=0.85,
            gaps_identified=["Falta informaci√≥n sobre regi√≥n LATAM"]
        )

        # Reportar al Lead Agent v√≠a message bus
        self.bus.publish(
            sender=f"{self.task.agent_role.value}_{self.task.id}",
            receiver="lead_agent",
            message=result
        )

        return result

class MultiAgentResearchSystem:
    """Sistema completo de investigaci√≥n multi-agente."""

    def __init__(self, llm_client):
        self.llm = llm_client
        self.message_bus = MessageBus()
        self.shared_memory = SharedMemory()
        self.lead_agent = LeadAgent(llm_client, self.message_bus, self.shared_memory)

    async def research(self, query: str) -> str:
        """
        Ejecuta investigaci√≥n multi-agente completa.

        Args:
            query: Query del usuario

        Returns:
            S√≠ntesis final de investigaci√≥n
        """
        print(f"üîç Iniciando investigaci√≥n: {query}\n")

        # Paso 1: Lead Agent crea plan
        print("üìã Lead Agent creando plan de investigaci√≥n...")
        tasks = await self.lead_agent.create_research_plan(query)
        print(f"‚úÖ Plan creado con {len(tasks)} tareas\n")

        # Paso 2: Crear subagents
        print("ü§ñ Creando subagents especializados...")
        subagents = [
            SubAgent(task, self.llm, self.message_bus, self.shared_memory)
            for task in tasks
        ]
        print(f"‚úÖ {len(subagents)} subagents creados\n")

        # Paso 3: Ejecutar investigaci√≥n en paralelo
        print("‚ö° Ejecutando investigaci√≥n en paralelo...")
        results = await asyncio.gather(*[
            agent.research() for agent in subagents
        ])
        print(f"‚úÖ Investigaci√≥n completada\n")

        # Paso 4: Sintetizar resultados
        print("üìä Sintetizando resultados...")
        synthesis = await self.lead_agent.synthesize_results(results)
        print("‚úÖ S√≠ntesis completada\n")

        return synthesis
```

Este c√≥digo implementa los conceptos clave del art√≠culo de Anthropic. En las pr√≥ximas secciones veremos c√≥mo expandirlo con memoria persistente, debugging, y el proyecto completo.

---

## Gesti√≥n de Memoria y Estado

### Problema: Context Limits

**Desaf√≠o**: Claude tiene un l√≠mite de 200,000 tokens. En investigaciones largas, el contexto puede excederse.

**Soluci√≥n del art√≠culo de Anthropic**:
1. **External Memory**: Lead Agent guarda el plan de investigaci√≥n en memoria externa
2. **Context Truncation**: Cuando se acerca al l√≠mite, trunca conservando lo esencial
3. **Stateful Handoffs**: Nuevos subagents heredan contexto desde memoria externa

### Implementaci√≥n de Memoria Persistente

```python
import json
from pathlib import Path
from datetime import datetime

class PersistentMemory(SharedMemory):
    """
    Memoria compartida con persistencia en disco.

    Permite:
    - Guardar estado entre sesiones
    - Recuperarse de errores
    - Auditar decisiones de agentes
    """

    def __init__(self, storage_dir: str = "./memory"):
        super().__init__()
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")

    def store(self, key: str, value: Any):
        """Almacena en memoria y persiste a disco."""
        super().store(key, value)

        # Persistir a disco
        file_path = self.storage_dir / f"{self.session_id}_{key}.json"
        with open(file_path, 'w') as f:
            json.dump({
                "key": key,
                "value": value,
                "timestamp": datetime.now().isoformat()
            }, f, indent=2, default=str)

    def retrieve(self, key: str) -> Any:
        """Recupera de memoria o disco."""
        # Intentar memoria primero
        value = super().retrieve(key)
        if value is not None:
            return value

        # Si no est√° en memoria, buscar en disco
        file_path = self.storage_dir / f"{self.session_id}_{key}.json"
        if file_path.exists():
            with open(file_path, 'r') as f:
                data = json.load(f)
                return data["value"]

        return None

    def checkpoint(self, checkpoint_name: str):
        """Crea checkpoint del estado actual."""
        checkpoint_data = {
            "session_id": self.session_id,
            "timestamp": datetime.now().isoformat(),
            "state": self._data
        }

        checkpoint_path = self.storage_dir / f"checkpoint_{checkpoint_name}.json"
        with open(checkpoint_path, 'w') as f:
            json.dump(checkpoint_data, f, indent=2, default=str)

        print(f"‚úÖ Checkpoint guardado: {checkpoint_name}")

    def restore_checkpoint(self, checkpoint_name: str):
        """Restaura estado desde checkpoint."""
        checkpoint_path = self.storage_dir / f"checkpoint_{checkpoint_name}.json"

        if not checkpoint_path.exists():
            raise FileNotFoundError(f"Checkpoint no encontrado: {checkpoint_name}")

        with open(checkpoint_path, 'r') as f:
            checkpoint_data = json.load(f)

        self._data = checkpoint_data["state"]
        print(f"‚úÖ Checkpoint restaurado: {checkpoint_name}")
```

### Memory Compartida vs Privada

**Memory Compartida** (SharedMemory):
- ‚úÖ Todos los agentes pueden leer/escribir
- ‚úÖ √ötil para: plan de investigaci√≥n, resultados agregados
- ‚ùå Riesgo: conflictos si m√∫ltiples agentes escriben simult√°neamente

**Memory Privada** (por agente):
- ‚úÖ Cada agente tiene su propio contexto
- ‚úÖ √ötil para: notas de investigaci√≥n, b√∫squedas intermedias
- ‚úÖ Sin conflictos

**Ejemplo**:
```python
class SubAgent:
    def __init__(self, task, llm, message_bus, shared_memory):
        self.task = task
        self.llm = llm
        self.bus = message_bus
        self.shared_memory = shared_memory  # Compartida
        self.private_memory = {}  # Privada

    async def research(self):
        # Escribir en memoria privada (solo este agente)
        self.private_memory["search_history"] = []

        # Leer de memoria compartida (todos los agentes)
        research_plan = self.shared_memory.retrieve("research_plan")

        # ...
```

---

## Debugging y Observabilidad

### Desaf√≠o

**Problema**: En un sistema multi-agente, cuando algo falla, ¬øc√≥mo sabes qu√© agente caus√≥ el error?

**Soluci√≥n**: Logging estructurado + tracing de decisiones.

### Logging Estructurado

```python
import logging
import json
from datetime import datetime

class AgentLogger:
    """Logger especializado para sistemas multi-agente."""

    def __init__(self, agent_id: str, log_file: str = "agents.log"):
        self.agent_id = agent_id
        self.logger = logging.getLogger(f"agent.{agent_id}")

        # Handler para archivo JSON
        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter('%(message)s'))
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)

    def log_decision(self, decision: str, context: Dict[str, Any]):
        """Registra una decisi√≥n del agente."""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "agent_id": self.agent_id,
            "event_type": "decision",
            "decision": decision,
            "context": context
        }
        self.logger.info(json.dumps(log_entry))

    def log_tool_call(self, tool: str, params: Dict[str, Any], result: Any):
        """Registra uso de herramienta."""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "agent_id": self.agent_id,
            "event_type": "tool_call",
            "tool": tool,
            "params": params,
            "result_preview": str(result)[:200]  # Truncar
        }
        self.logger.info(json.dumps(log_entry))

    def log_error(self, error: Exception, context: Dict[str, Any]):
        """Registra error."""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "agent_id": self.agent_id,
            "event_type": "error",
            "error_type": type(error).__name__,
            "error_message": str(error),
            "context": context
        }
        self.logger.error(json.dumps(log_entry))
```

**Uso**:
```python
class SubAgent:
    def __init__(self, task, llm, message_bus, shared_memory):
        # ...
        self.logger = AgentLogger(f"{task.agent_role}_{task.id}")

    async def research(self):
        self.logger.log_decision(
            "Starting research",
            {"task_id": self.task.id, "description": self.task.description}
        )

        # Simular b√∫squeda
        self.logger.log_tool_call(
            "web_search",
            {"query": "IA in automotive"},
            {"results": 10, "sources": ["..."]}
        )

        # ...
```

### Tracing de Interacciones

**Visualizar flujo de mensajes** entre agentes:

```python
class MessageBus:
    def __init__(self):
        self._messages = []
        self.trace_file = "message_trace.json"

    def publish(self, sender: str, receiver: str, message: Any):
        msg_entry = {
            "timestamp": datetime.now().isoformat(),
            "sender": sender,
            "receiver": receiver,
            "message_type": type(message).__name__,
            "message_preview": str(message)[:100]
        }

        self._messages.append(msg_entry)

        # Persistir trace
        with open(self.trace_file, 'a') as f:
            f.write(json.dumps(msg_entry) + "\n")

    def export_trace(self) -> str:
        """Exporta trace completo para an√°lisis."""
        return json.dumps(self._messages, indent=2)
```

**An√°lisis post-mortem**:
```bash
# Ver todos los mensajes
cat message_trace.json | jq '.sender, .receiver, .message_type'

# Ver mensajes de un agente espec√≠fico
cat message_trace.json | jq 'select(.sender == "researcher_1")'
```

---

## Proyecto: Sistema de Research para Documentaci√≥n

### Objetivo

Construir un sistema multi-agente que **genere documentaci√≥n t√©cnica completa** para un proyecto de c√≥digo.

**Input**: Repositorio de c√≥digo (ej: FastAPI project)
**Output**: Documentaci√≥n markdown profesional con:
- README.md
- API_REFERENCE.md
- ARCHITECTURE.md
- DEPLOYMENT.md

### Agentes Especializados

1. **CodeAnalyzer Agent**: Analiza el c√≥digo fuente
2. **APIDocumenter Agent**: Genera documentaci√≥n de API
3. **ArchitectureMapper Agent**: Crea diagramas de arquitectura
4. **DeploymentGuide Agent**: Escribe gu√≠a de deployment
5. **WriterAgent**: Redacta documentaci√≥n final

### Implementaci√≥n

Ver carpeta `ejemplos/documentation_system/` para c√≥digo completo.

**Ejemplo de ejecuci√≥n**:
```python
# main.py
from multi_agent_system.documentation import DocumentationSystem

async def main():
    system = DocumentationSystem(llm_client)

    docs = await system.generate_documentation(
        repo_path="./my-fastapi-project",
        output_dir="./docs"
    )

    print(f"‚úÖ Documentaci√≥n generada en: {docs.output_dir}")

asyncio.run(main())
```

**Output esperado**:
```
docs/
‚îú‚îÄ‚îÄ README.md (overview del proyecto)
‚îú‚îÄ‚îÄ API_REFERENCE.md (endpoints documentados)
‚îú‚îÄ‚îÄ ARCHITECTURE.md (diagramas + decisiones)
‚îî‚îÄ‚îÄ DEPLOYMENT.md (gu√≠a de deployment)
```

---

## Ejercicios Pr√°cticos

### Ejercicio 1: Sistema de Research de 2 Agentes

**Objetivo**: Implementar un sistema simple con 1 Lead Agent + 1 Subagent.

**Task**: Investiga "Lenguajes de programaci√≥n m√°s populares en 2024"

**Requisitos**:
- Lead Agent divide en 2 subtareas
- 2 Subagents investigan en paralelo
- Lead Agent sintetiza resultados

**Criterio de √©xito**: Respuesta con datos de al menos 2 fuentes distintas.

### Ejercicio 2: Sistema con Citation Verifier

**Objetivo**: Agregar validaci√≥n de fuentes.

**Task**: Usa el sistema del Ejercicio 1, pero agrega un CitationAgent que:
- Verifica que cada claim tenga fuente
- Valida URLs accesibles
- Genera score de credibilidad

### Ejercicio 3: Sistema de Documentaci√≥n (Proyecto Final)

**Objetivo**: Implementar el sistema completo de documentaci√≥n t√©cnica.

**Task**: Genera documentaci√≥n para un proyecto FastAPI real.

**Requisitos**:
- 5 agentes especializados
- Memoria persistente (checkpoints)
- Logging estructurado
- Output en markdown profesional

---

## Recursos Adicionales

### Art√≠culos de Anthropic (Lectura Obligatoria)

1. **[Multi-Agent Research System](https://www.anthropic.com/engineering/multi-agent-research-system)** ‚≠ê BASE DE ESTA CLASE
   - Arquitectura real de Anthropic
   - Patrones de comunicaci√≥n
   - M√©tricas de performance

2. **[Effective Context Engineering](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)**
   - Memory management
   - Context truncation strategies

3. **[Agent Skills Framework](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)**
   - Composici√≥n de habilidades
   - Especializaci√≥n de agentes

### Frameworks y Herramientas

- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Framework para sistemas multi-agente
- **[AutoGen](https://microsoft.github.io/autogen/)**: Microsoft's multi-agent framework
- **[CrewAI](https://github.com/joaomdmoura/crewAI)**: Framework para equipos de agentes

### Papers Acad√©micos

- "Communicating Agent Architectures" (Multi-agent systems)
- "Hierarchical Reinforcement Learning with Subgoals" (Task decomposition)

---

## Glosario

- **Lead Agent**: Agente orquestador que planifica y coordina
- **Subagent**: Agente worker especializado en una subtarea
- **Query Decomposition**: Dividir query compleja en subtareas
- **Result Synthesis**: Agregar resultados de m√∫ltiples agentes
- **Extended Thinking**: Modo de razonamiento profundo para planificaci√≥n
- **Interleaved Thinking**: Razonamiento intercalado durante ejecuci√≥n
- **Message Passing**: Comunicaci√≥n entre agentes via mensajes
- **Shared Memory**: Memoria accesible por todos los agentes
- **Private Memory**: Memoria exclusiva de un agente
- **Citation Agent**: Agente que verifica fuentes y citaciones
- **Breadth-first Search**: Estrategia de b√∫squeda amplia antes de profunda
- **Token Budget**: L√≠mite de tokens en contexto del LLM
- **Context Truncation**: Reducir contexto para evitar exceder l√≠mite
- **Checkpoint**: Snapshot del estado del sistema para recuperaci√≥n

---

## Reflexi√≥n Final

Al completar esta clase, deber√≠as poder responder:

1. **¬øCu√°ndo usar multi-agente vs un solo agente?**
   - Multi-agente: Tareas complejas que requieren especializaci√≥n
   - Single-agente: Tareas simples, lineales

2. **¬øCu√°l es el trade-off principal?**
   - ‚úÖ Mayor calidad y profundidad
   - ‚ùå Mayor costo en tokens (15x seg√∫n Anthropic)
   - ‚úÖ Pero: 90.2% mejor performance en tareas complejas

3. **¬øC√≥mo evitar trabajo duplicado entre agentes?**
   - Instrucciones espec√≠ficas (no vagas)
   - Divisi√≥n clara de responsabilidades
   - Lead Agent coordina y evita overlap

4. **¬øQu√© aprendiste sobre coordinaci√≥n?**
   - La coordinaci√≥n es el reto principal
   - Message passing debe ser claro
   - Memoria compartida requiere gesti√≥n cuidadosa

---

**Siguiente clase**: [Clase 5 - Agent Orchestration Mastery](../Clase%205%20-%20Agent%20Orchestration%20Mastery/README.md) - Aplicar√°s estos conceptos para orquestar equipos completos de agentes en proyectos reales.

**Clase anterior**: [Clase 4 - Despliegue Full-Stack](../Clase%204%20-%20Despliegue%20Full-Stack/README.md)

---

**üéØ Logros de esta clase**:
- ‚úÖ Entiendes arquitectura multi-agente
- ‚úÖ Puedes dividir tareas complejas en subtareas
- ‚úÖ Implementaste sistema de research b√°sico
- ‚úÖ Conoces patrones de comunicaci√≥n entre agentes
- ‚úÖ Sabes gestionar memoria y estado
- ‚úÖ Puedes debuggear sistemas multi-agente
